{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5e143b",
   "metadata": {},
   "source": [
    "# Quick start\n",
    "\n",
    "*EPAM Syngen* is an unsupervised tabular data generation tool based on a variational autoencoder (VAE). \n",
    "It supports common tabular datatypes (floats, integers, datetime, text, categorical, binary) and can generate linked tables that sharing keys using the simple statistical approach. \n",
    "The SDK exposes simple programmatic entry points for training, inference, report generation, loading and saving data in supported formats - *CSV*, *Avro* and *Excel* format. The data should be located locally and be in UTF-8 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b1de2",
   "metadata": {},
   "source": [
    "This notebook demonstrates the SDK usage. Install the package and then you can call the main SDK class `Syngen` to run training, inference or generation of reports, and the class `DataIO` to load and save the data in supported formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe338621",
   "metadata": {},
   "source": [
    "Python *3.10* or *3.11* is required to run the library. The library is tested on Linux and Windows operating systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f88606",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "Please, install the library *syngen* (from Pypi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbdea6c32caa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/, https://pypi.org/simple/\n",
      "Collecting syngen==0.10.33rc7\n",
      "  Downloading https://test-files.pythonhosted.org/packages/5f/d7/4a5f82b7c9f4876ff82b98c6b91beeaca42043a50773efdef8b69cfdd82c/syngen-0.10.33rc7-py3-none-any.whl.metadata (45 kB)\n",
      "Requirement already satisfied: aiohttp>=3.10.11 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (3.13.3)\n",
      "Requirement already satisfied: attrs in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (25.4.0)\n",
      "Requirement already satisfied: avro in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (1.12.1)\n",
      "Requirement already satisfied: base32-crockford in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (0.3.0)\n",
      "Requirement already satisfied: boto3 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (1.42.21)\n",
      "Requirement already satisfied: click in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (8.3.1)\n",
      "Requirement already satisfied: cryptography in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (46.0.3)\n",
      "Requirement already satisfied: Jinja2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (3.1.6)\n",
      "Requirement already satisfied: keras==2.15.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (2.15.0)\n",
      "Requirement already satisfied: lazy==1.4 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (1.4)\n",
      "Requirement already satisfied: loguru in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (0.7.3)\n",
      "Requirement already satisfied: MarkupSafe==2.1.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (2.1.1)\n",
      "Requirement already satisfied: marshmallow==3.19.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (3.19.0)\n",
      "Requirement already satisfied: matplotlib==3.9.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (3.9.4)\n",
      "Requirement already satisfied: mlflow==3.8.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (3.8.2)\n",
      "Requirement already satisfied: numpy==1.26.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (1.26.4)\n",
      "Requirement already satisfied: openpyxl in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (3.1.5)\n",
      "Requirement already satisfied: pandas==2.2.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (2.2.3)\n",
      "Requirement already satisfied: pandavro==1.8.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (1.8.0)\n",
      "Requirement already satisfied: pathos==0.2.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (0.2.9)\n",
      "Requirement already satisfied: pillow==10.3.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (10.3.0)\n",
      "Requirement already satisfied: psutil in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (7.2.1)\n",
      "Requirement already satisfied: py-ulid in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (1.0.3)\n",
      "Requirement already satisfied: pytest in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (9.0.2)\n",
      "Requirement already satisfied: pytest-reportportal in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (5.6.0)\n",
      "Requirement already satisfied: python-slugify>=7.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from python-slugify[unidecode]>=7.0.0->syngen==0.10.33rc7) (8.0.4)\n",
      "Requirement already satisfied: PyYAML==6.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (6.0.3)\n",
      "Requirement already satisfied: reportportal-client in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (5.7.0)\n",
      "Requirement already satisfied: scikit_learn==1.5.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (1.5.2)\n",
      "Requirement already satisfied: scipy==1.14.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (1.14.1)\n",
      "Requirement already satisfied: seaborn==0.13.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (0.13.2)\n",
      "Requirement already satisfied: setuptools==78.1.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (78.1.1)\n",
      "Requirement already satisfied: tensorflow==2.15.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (2.15.1)\n",
      "Requirement already satisfied: tornado==6.5.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (6.5.4)\n",
      "Requirement already satisfied: tqdm==4.66.3 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (4.66.3)\n",
      "Requirement already satisfied: Werkzeug==3.1.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (3.1.4)\n",
      "Requirement already satisfied: xlrd in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (2.0.2)\n",
      "Requirement already satisfied: xlwt in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc7) (1.3.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from marshmallow==3.19.*->syngen==0.10.33rc7) (25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from matplotlib==3.9.*->syngen==0.10.33rc7) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from matplotlib==3.9.*->syngen==0.10.33rc7) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from matplotlib==3.9.*->syngen==0.10.33rc7) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from matplotlib==3.9.*->syngen==0.10.33rc7) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from matplotlib==3.9.*->syngen==0.10.33rc7) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from matplotlib==3.9.*->syngen==0.10.33rc7) (2.9.0.post0)\n",
      "Requirement already satisfied: mlflow-skinny==3.8.2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (3.8.2)\n",
      "Requirement already satisfied: mlflow-tracing==3.8.2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (3.8.2)\n",
      "Requirement already satisfied: Flask-CORS<7 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (6.0.2)\n",
      "Requirement already satisfied: Flask<4 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (1.17.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (23.0.0)\n",
      "Requirement already satisfied: huey<3,>=2.5.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (2.5.5)\n",
      "Requirement already satisfied: pyarrow<23,>=4.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (22.0.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow==3.8.*->syngen==0.10.33rc7) (2.0.45)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (6.2.4)\n",
      "Requirement already satisfied: cloudpickle<4 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (3.1.2)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.76.0)\n",
      "Requirement already satisfied: fastapi<1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.128.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (3.1.46)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (8.7.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (1.39.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (4.25.8)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (2.12.5)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (1.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (2.32.5)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.5.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (4.15.0)\n",
      "Requirement already satisfied: uvicorn<1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.40.0)\n",
      "Requirement already satisfied: Mako in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow==3.8.*->syngen==0.10.33rc7) (1.3.10)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from cryptography->syngen==0.10.33rc7) (2.0.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (2.41.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow==3.8.*->syngen==0.10.33rc7) (2.6.2)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.0.4)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from Flask<4->mlflow==3.8.*->syngen==0.10.33rc7) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from Flask<4->mlflow==3.8.*->syngen==0.10.33rc7) (2.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from graphene<4->mlflow==3.8.*->syngen==0.10.33rc7) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from graphene<4->mlflow==3.8.*->syngen==0.10.33rc7) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.60b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pandas==2.2.*->syngen==0.10.33rc7) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pandas==2.2.*->syngen==0.10.33rc7) (2025.3)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.5.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pandavro==1.8.*->syngen==0.10.33rc7) (1.12.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pathos==0.2.*->syngen==0.10.33rc7) (1.7.7)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pathos==0.2.*->syngen==0.10.33rc7) (0.4.0)\n",
      "Requirement already satisfied: pox>=0.3.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pathos==0.2.*->syngen==0.10.33rc7) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pathos==0.2.*->syngen==0.10.33rc7) (0.70.18)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.9.*->syngen==0.10.33rc7) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (2026.1.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from scikit_learn==1.5.*->syngen==0.10.33rc7) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from scikit_learn==1.5.*->syngen==0.10.33rc7) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==3.8.*->syngen==0.10.33rc7) (3.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (4.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (0.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (3.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (3.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (3.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (1.14.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (1.76.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorflow==2.15.*->syngen==0.10.33rc7) (2.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc7) (1.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc7) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc7) (0.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc7) (2.0.0)\n",
      "Requirement already satisfied: h11>=0.8 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc7) (0.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from aiohttp>=3.10.11->syngen==0.10.33rc7) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from aiohttp>=3.10.11->syngen==0.10.33rc7) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from aiohttp>=3.10.11->syngen==0.10.33rc7) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from aiohttp>=3.10.11->syngen==0.10.33rc7) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from aiohttp>=3.10.11->syngen==0.10.33rc7) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from aiohttp>=3.10.11->syngen==0.10.33rc7) (1.22.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.15.*->syngen==0.10.33rc7) (0.45.1)\n",
      "Requirement already satisfied: pycparser in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography->syngen==0.10.33rc7) (2.23)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from python-slugify>=7.0.0->python-slugify[unidecode]>=7.0.0->syngen==0.10.33rc7) (1.3)\n",
      "Requirement already satisfied: Unidecode>=1.1.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from python-slugify[unidecode]>=7.0.0->syngen==0.10.33rc7) (1.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc7) (3.3.1)\n",
      "Requirement already satisfied: botocore<1.43.0,>=1.42.21 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from boto3->syngen==0.10.33rc7) (1.42.21)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from boto3->syngen==0.10.33rc7) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from boto3->syngen==0.10.33rc7) (0.16.0)\n",
      "Requirement already satisfied: et-xmlfile in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from openpyxl->syngen==0.10.33rc7) (2.0.0)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pytest->syngen==0.10.33rc7) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pytest->syngen==0.10.33rc7) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pytest->syngen==0.10.33rc7) (2.19.2)\n",
      "Requirement already satisfied: aenum>=3.1.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pytest-reportportal->syngen==0.10.33rc7) (3.1.16)\n",
      "Downloading https://test-files.pythonhosted.org/packages/5f/d7/4a5f82b7c9f4876ff82b98c6b91beeaca42043a50773efdef8b69cfdd82c/syngen-0.10.33rc7-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: syngen\n",
      "  Attempting uninstall: syngen\n",
      "    Found existing installation: syngen 0.10.33rc4\n",
      "    Uninstalling syngen-0.10.33rc4:\n",
      "      Successfully uninstalled syngen-0.10.33rc4\n",
      "Successfully installed syngen-0.10.33rc7\n"
     ]
    }
   ],
   "source": [
    "!pip install  --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ --use-pep517 --no-cache-dir syngen==0.10.33rc8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3ce41",
   "metadata": {},
   "source": [
    "# Class initialization\n",
    "\n",
    "```python\n",
    "Syngen(\n",
    "    metadata_path: Optional[str] = None,  # use a metadata file in the '.yaml', '.yml' format for a training or an inference of one or multiple tables to centralize all parameters in one place\n",
    "    table_name: Optional[str] = None,     # required for a single-table training or inference process; an arbitrary string used to name the directories where artifacts are stored\n",
    "    source: Optional[str] = None,         # optional for a single-table training or inference process; a path to the file that you want to use as a reference\n",
    "    loader: Optional[Callable[[str], pd.DataFrame]] # optional for a training or inference process of one or multiple tables; a callback function that returns the sample of the original data of a certain table\n",
    ")\n",
    "```\n",
    "### Attributes description:\n",
    "\n",
    "- **`metadata_path`** *(Optional[str], default: None)*: a path to a metadata file in *'.yaml'* or *'.yml'* format, used during a training or inference processes to centralize all parameters for one or multiple tables in one place.\n",
    "- **`table_name`** *(Optional[str], default: None)*: a required parameter for a training or inference processes of a single table; an arbitrary string used to name the directories where artifacts are stored.\n",
    "- **`source`** *(Optional[str], default: None)*: an optional parameter for a single-table training or inference process; a path to the file that you want to use as a reference.\n",
    "- **`loader`** *(Optional[str], default: None)*: an optional parameter for a training or inference process of one or multiple tables; a callback function that returns the sample of the original data of a certain table.\n",
    "\n",
    "***Note***: You can provide the information about required attributes in one of three ways:\n",
    "1. Use `metadata_path` to define the metadata of one or multiple tables and their relationships in one place.\n",
    "2. Using `table_name` and `source`: For a single-table training or inference process, provide both `table_name` and `source` if the original data is supplied directly from a `source`.\n",
    "3. Using `table_name` and `loader`: For a single-table training or inference process, provide both `table_name` and `loader` if the original data is supplied via a callback function (`loader`).\n",
    "4. Using `metadata_path` and `loader`: For a training or inference process of one or multiple tables if the original data of tables is supplied via a callback function (`loader`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6d2562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 11:06:40.813521: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-13 11:06:40.813581: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-13 11:06:40.960150: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# The example of the initialization of the instance of the class 'Syngen' for the single-table training or inference process\n",
    "# by providing the `source` and 'table_name' parameters\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "\n",
    "launcher_for_single_table_with_source = Syngen(\n",
    "    source=\"../examples/example-data/housing.csv\", \n",
    "    table_name=\"housing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe83fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of the initialization of the instance of the class 'Syngen' for the single-table training or inference process \n",
    "# by providing the `loader` and 'table_name' parameters\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "\n",
    "\n",
    "def get_dataframe(table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    The demonstration callback function to load a CSV file \n",
    "    and get a pandas DataFrame from the 'example-data' directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name : str\n",
    "        The name of the table (the name of the file without extension) to load\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The loaded data as a pandas DataFrame\n",
    "    \"\"\"\n",
    "    path_to_example_data = f\"../examples/example-data/{table_name}.csv\"\n",
    "    \n",
    "    if not os.path.exists(path_to_example_data):\n",
    "        raise FileNotFoundError(f\"The CSV file '{table_name}.csv' does not exist\")\n",
    "    \n",
    "    return pd.read_csv(path_to_example_data)\n",
    "\n",
    "\n",
    "\n",
    "launcher_for_single_table_with_loader = Syngen(\n",
    "    loader=get_dataframe, \n",
    "    table_name=\"housing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8bb26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of the initialization of the instance of the class 'Syngen' for multiple tables\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables = Syngen(\n",
    "    metadata_path=\"../examples/example-metadata/housing_metadata.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1c86c",
   "metadata": {},
   "source": [
    "# Launch training\n",
    "\n",
    "You can start a training process using the SDK entrypoint `Syngen().train(...)`. This will train a model and save the model artifacts to a disk in the directory *'./model_artifacts'*. The SDK mirrors the CLI options so you can pass the same parameters programmatically. Below is a complete description of all available parameters:\n",
    "\n",
    "```python\n",
    "train(\n",
    "    self,\n",
    "    epochs: int = 10,                     # a number of training epochs\n",
    "    drop_null: bool = False,              # whether to drop rows with at least one missing value\n",
    "    row_limit: Optional[int] = None,      # a number of rows to train over\n",
    "    reports: Union[str, Tuple[str], List[str]] = \"none\",  # report types: \"none\", \"accuracy\", \"sample\", \"metrics_only\", \"all\"\n",
    "    log_level: Literal[\"TRACE\", \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"] = \"INFO\", # a logging level\n",
    "    batch_size: int = 32,                 # a training batch size\n",
    "    fernet_key: Optional[str] = None      # a name of the environment variable containing the Fernet key for secure storage of the data subset\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters description:\n",
    "\n",
    "- **`epochs`** *(int, default: 10)*: A number of training epochs. Must be ≥ 1. Since the early stopping mechanism is implemented the bigger value of epochs is the better.\n",
    "\n",
    "- **`drop_null`** *(bool, default: False)*: Whether to drop rows containing at least one missing value before training. When `False`, missing values are handled during the training process.\n",
    "\n",
    "- **`row_limit`** *(Optional[int], default: None)*: A maximum number of rows to use for training. If specified and less than the total rows, a random subset of the specified size will be selected. Useful for testing or working with large datasets.\n",
    "\n",
    "- **`reports`** *(Union[str, Tuple[str], List[str]], default: \"none\")*: Controls generation of quality reports. Accepts single string or list of strings:\n",
    "  - `\"none\"` - no reports generated (default)\n",
    "  - `\"accuracy\"` - generates an accuracy report comparing synthetic data (same size as original) with original dataset to estimate the quality of training process\n",
    "  - `\"sample\"` - generates a sample report showing distribution comparisons between the original data and the subset of this data\n",
    "  - `\"metrics_only\"` - outputs metrics to stdout without generation of an accuracy report\n",
    "  - `\"all\"` - generates both accuracy and sample reports\n",
    "\n",
    "  List example: `[\"accuracy\", \"sample\"]` to generate multiple report types\n",
    "\n",
    "  *Note*: Report generation may require significant time for large tables (>10,000 rows)\n",
    "\n",
    "- **`log_level`** *(str, default: \"INFO\")*: A logging level for the training process. Accepted values: `\"TRACE\"`, `\"DEBUG\"`, `\"INFO\"`, `\"WARNING\"`, `\"ERROR\"`, `\"CRITICAL\"`.\n",
    "\n",
    "- **`batch_size`** *(int, default: 32)*: A training batch size. Must be ≥ 1. Splits training into batches to optimize memory usage. Smaller batches use less RAM but may increase training time.\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: A name of the environment variable containing a 44-character URL-safe base64-encoded Fernet key. When provided, the data subset is encrypted on a disk (stored in the `.dat` format). If not provided, data is stored unencrypted in the `.pkl` format. **Important**: The same key must be used during an inference and a report generation to decrypt the data.\n",
    "\n",
    "\n",
    "*Note:* For full documentation, metadata file format, and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1a8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-13 11:11:18.283\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.validation_schema.validation_schema\u001b[0m:\u001b[36mvalidate_schema\u001b[0m:\u001b[36m348\u001b[0m - \u001b[34m\u001b[1mThe schema of the metadata is valid\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/resources/housing/' was removed\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_collect_errors\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1mThe validation of the metadata has been passed successfully\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.296\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcheck_mlflow_server\u001b[0m:\u001b[36m32\u001b[0m - \u001b[33m\u001b[1mMLFlow server URL not provided\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.296\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcreate_tracker\u001b[0m:\u001b[36m69\u001b[0m - \u001b[33m\u001b[1mMLFlow server is either unreachable or not set up, therefore the tracking will not be performed\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.train\u001b[0m:\u001b[36mlaunch_train\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe training process will be executed according to the information mentioned in 'train_settings' in the metadata file. If appropriate information is absent from the metadata file, then the values of parameters sent through CLI will be used. Otherwise, the values of parameters will be defaulted.\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.processors.processors\u001b[0m:\u001b[36m_preprocess_data\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mThe subset of rows was set to 1000\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_train_table\u001b[0m:\u001b[36m431\u001b[0m - \u001b[1mTraining process of the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mStart VAE training\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_pk_key\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mNo primary key was set.\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_uq_keys\u001b[0m:\u001b[36m267\u001b[0m - \u001b[1mNo unique keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_fk_keys\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mNo foreign keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.388\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_detection_pipeline\u001b[0m:\u001b[36m1081\u001b[0m - \u001b[34m\u001b[1mCount of string columns: 0; Count of email columns: 0; Count of float columns: 3; Count of int columns: 6; Count of categorical columns: 1; Count of date columns: 0; Count of binary columns: 0; Count of long text columns: 0; Count of uuid columns: 0\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'longitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'latitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'housing_median_age' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_rooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_preprocess_nan_cols\u001b[0m:\u001b[36m1206\u001b[0m - \u001b[1mColumn 'total_bedrooms' contains 16 (1.6%) empty values out of 1000. Filling them with mean.\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_bedrooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mColumn 'total_bedrooms_null' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'population' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'households' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'median_income' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'median_house_value' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_categ_feature\u001b[0m:\u001b[36m1392\u001b[0m - \u001b[1mColumn 'ocean_proximity' assigned as categorical based feature.\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:18.884\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m178\u001b[0m - \u001b[34m\u001b[1mTrain model with parameters: epochs=5, row_subset=1000, drop_null=False, batch_size=100, reports - 'accuracy', 'sample'\u001b[0m\n",
      "10it [00:01,  9.31it/s]\n",
      "\u001b[32m2026-01-13 11:11:20.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 0, total loss: 2.7531943321228027, time: 1.1563 sec\u001b[0m\n",
      "10it [00:00, 13.03it/s]\n",
      "\u001b[32m2026-01-13 11:11:20.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 1, total loss: 2.396063804626465, time: 0.7954 sec\u001b[0m\n",
      "10it [00:00, 13.01it/s]\n",
      "\u001b[32m2026-01-13 11:11:21.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 2, total loss: 2.1226084232330322, time: 0.7935 sec\u001b[0m\n",
      "10it [00:00, 12.85it/s]\n",
      "\u001b[32m2026-01-13 11:11:22.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 3, total loss: 1.9315086603164673, time: 0.8067 sec\u001b[0m\n",
      "10it [00:00, 12.93it/s]\n",
      "\u001b[32m2026-01-13 11:11:23.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 4, total loss: 1.8451658487319946, time: 0.8000 sec\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:23.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFit sampler\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:23.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mStart encoding\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 790us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-13 11:11:23.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m187\u001b[0m - \u001b[1mCreating BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:23.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mFitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:25.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished fitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:25.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36msave_state\u001b[0m:\u001b[36m545\u001b[0m - \u001b[1mSaved VAE state in model_artifacts/resources/housing/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:25.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished VAE training\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:25.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mNo columns to train kde over found\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:25.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mTraining of the table - 'housing' was completed\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:25.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m519\u001b[0m - \u001b[1mInfer process of the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-13 11:11:25.387\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m228\u001b[0m - \u001b[31m\u001b[1mGeneration of the table - 'housing' failed on running stage.\n",
      "The traceback of the error - Traceback (most recent call last):\n",
      "  File \"/home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/ml/strategies/strategies.py\", line 222, in run\n",
      "    self.set_config(**kwargs)\n",
      "  File \"/home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/ml/strategies/strategies.py\", line 165, in set_config\n",
      "    configuration = InferConfig(**kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: InferConfig.__init__() got an unexpected keyword argument 'loader'\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "InferConfig.__init__() got an unexpected keyword argument 'loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# The example of a training the single table on the provided data fetching it via the 'source' parameter\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mlauncher_for_single_table_with_source\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_null\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrow_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreports\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_level\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDEBUG\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/sdk.py:325\u001b[39m, in \u001b[36mSyngen.train\u001b[39m\u001b[34m(self, epochs, drop_null, row_limit, reports, log_level, batch_size, fernet_key)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\n\u001b[32m    316\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    317\u001b[39m     epochs: \u001b[38;5;28mint\u001b[39m = \u001b[32m10\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m     fernet_key: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    324\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[43mlaunch_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetadata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdrop_null\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrow_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreports\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreports\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_level\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfernet_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfernet_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_execution_artifacts(type_of_process=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/train.py:111\u001b[39m, in \u001b[36mlaunch_train\u001b[39m\u001b[34m(metadata_path, source, table_name, epochs, drop_null, row_limit, reports, log_level, batch_size, fernet_key, loader)\u001b[39m\n\u001b[32m     83\u001b[39m worker = Worker(\n\u001b[32m     84\u001b[39m     table_name=table_name,\n\u001b[32m     85\u001b[39m     metadata_path=metadata_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m     loader=loader\n\u001b[32m    102\u001b[39m )\n\u001b[32m    104\u001b[39m logger.info(\n\u001b[32m    105\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe training process will be executed according to the information mentioned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33min \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain_settings\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in the metadata file. If appropriate information is absent \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrom the metadata file, then the values of parameters sent through CLI will be used. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOtherwise, the values of parameters will be defaulted.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/ml/worker/worker.py:651\u001b[39m, in \u001b[36mWorker.launch_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    641\u001b[39m (\n\u001b[32m    642\u001b[39m     tables_for_inference,\n\u001b[32m    643\u001b[39m     metadata_for_inference,\n\u001b[32m    644\u001b[39m ) = metadata_for_inference\n\u001b[32m    646\u001b[39m generation_of_synth_data = \u001b[38;5;28mself\u001b[39m._should_generate_synth_data(\n\u001b[32m    647\u001b[39m     metadata_for_training,\n\u001b[32m    648\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__train_tables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtables_for_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtables_for_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata_for_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata_for_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_of_synth_data\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28mself\u001b[39m._collect_metrics_in_train(\n\u001b[32m    659\u001b[39m     tables_for_training,\n\u001b[32m    660\u001b[39m     tables_for_inference,\n\u001b[32m    661\u001b[39m     generation_of_synth_data\n\u001b[32m    662\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/ml/worker/worker.py:478\u001b[39m, in \u001b[36mWorker.__train_tables\u001b[39m\u001b[34m(self, tables_for_training, tables_for_inference, metadata_for_training, metadata_for_inference, generation_of_synth_data)\u001b[39m\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m._train_table(data, schema, table, metadata_for_training, delta)\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m generation_of_synth_data:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__infer_tables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtables_for_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata_for_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28mself\u001b[39m._generate_reports()\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m generation_of_synth_data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/ml/worker/worker.py:567\u001b[39m, in \u001b[36mWorker.__infer_tables\u001b[39m\u001b[34m(self, tables, config_of_tables, delta, type_of_process)\u001b[39m\n\u001b[32m    564\u001b[39m non_surrogate_tables = [table \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables \u001b[38;5;28;01mif\u001b[39;00m table \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.divided]\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m non_surrogate_tables:\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_infer_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_of_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelta\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m tables_mapping = \u001b[38;5;28mself\u001b[39m._get_surrogate_tables_mapping()\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m table_root \u001b[38;5;129;01min\u001b[39;00m tables_mapping.keys():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/ml/worker/worker.py:529\u001b[39m, in \u001b[36mWorker._infer_table\u001b[39m\u001b[34m(self, table, metadata, type_of_process, delta, is_nested)\u001b[39m\n\u001b[32m    522\u001b[39m settings = config_of_table[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_of_process\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_settings\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    524\u001b[39m MlflowTracker().start_run(\n\u001b[32m    525\u001b[39m         run_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-INFER\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    526\u001b[39m         tags={\u001b[33m\"\u001b[39m\u001b[33mtable_name\u001b[39m\u001b[33m\"\u001b[39m: table, \u001b[33m\"\u001b[39m\u001b[33mprocess\u001b[39m\u001b[33m\"\u001b[39m: type_of_process},\n\u001b[32m    527\u001b[39m         nested=is_nested,\n\u001b[32m    528\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m529\u001b[39m \u001b[43mInferStrategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdestination\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minfer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetadata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minfer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_parallel\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_parallel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minfer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minfer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrandom_seed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minfer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreports\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreports\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_level\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboth_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mboth_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtype_of_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m ProgressBarHandler().set_progress(\n\u001b[32m    545\u001b[39m     delta=delta,\n\u001b[32m    546\u001b[39m     message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInfer process of the table - \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m was completed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m )\n\u001b[32m    548\u001b[39m MlflowTracker().end_run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/ml/strategies/strategies.py:222\u001b[39m, in \u001b[36mInferStrategy.run\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m table_name = kwargs[\u001b[33m\"\u001b[39m\u001b[33mtable_name\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m     MlflowTracker().log_params(\u001b[38;5;28mself\u001b[39m.config.to_dict())\n\u001b[32m    224\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_reporters()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/ml/strategies/strategies.py:165\u001b[39m, in \u001b[36mInferStrategy.set_config\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_config\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    Set up the configuration for infer process\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     configuration = \u001b[43mInferConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28mself\u001b[39m.config = configuration\n\u001b[32m    167\u001b[39m     \u001b[38;5;28mself\u001b[39m.metadata = deepcopy(\u001b[38;5;28mself\u001b[39m.config.metadata)\n",
      "\u001b[31mTypeError\u001b[39m: InferConfig.__init__() got an unexpected keyword argument 'loader'"
     ]
    }
   ],
   "source": [
    "# The example of a training the single table on the provided data fetching it via the 'source' parameter\n",
    "\n",
    "\n",
    "launcher_for_single_table_with_source.train(\n",
    "    epochs=5,\n",
    "    drop_null=False,\n",
    "    row_limit=1000, \n",
    "    batch_size=100,\n",
    "    reports=\"all\",\n",
    "    log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of training the single table on the provided data fetching it via the 'loader' parameter\n",
    "\n",
    "\n",
    "launcher_for_single_table_with_loader.train(\n",
    "    epochs=5,\n",
    "    drop_null=False,\n",
    "    row_limit=1000, \n",
    "    batch_size=100, \n",
    "    reports=\"all\",\n",
    "    log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f378a17c58f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of training of multiple tables with relationships\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.train(log_level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18988c75",
   "metadata": {},
   "source": [
    "The *'execution_artifacts'* attribute of the **Syngen** class provides information about the generated artifacts during the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(launcher_for_multiple_tables.execution_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf34c2c",
   "metadata": {},
   "source": [
    "# Launch generation of synthetic data\n",
    "\n",
    "You can start an inference process using the SDK entrypoint `Syngen().infer(...)`. The SDK mirrors the CLI options so you can pass the same parameters programmatically. Below is a complete description of all available parameters:\n",
    "\n",
    "```python\n",
    "infer(\n",
    "    self,\n",
    "    size: int = 100,                      # the desired number of rows to generate\n",
    "    run_parallel: bool = False,           # whether to use multiprocessing (feasible for tables > 50000 rows)\n",
    "    batch_size: Optional[int] = None,     # an inference batch size\n",
    "    random_seed: Optional[int] = None,    # if specified, generates a reproducible result\n",
    "    reports: Union[str, List[str]] = \"none\",  # report types: \"none\", \"accuracy\", \"metrics_only\", \"all\"\n",
    "    log_level: str = \"INFO\",              # a logging level\n",
    "    fernet_key: Optional[str] = None      # a name of the environment variable containing the Fernet key for decrypting the data subset\n",
    ")\n",
    "```\n",
    "### Parameters description:\n",
    "\n",
    "- **`size`** *(int, default: 100)*: The desired number of synthetic rows to generate. Must be ≥ 1.\n",
    "\n",
    "- **`run_parallel`** *(bool, default: False)*: Whether to use multiprocessing for data generation. Set to `True` to enable parallel processing, which is recommended and feasible for generating large tables (> 50000 rows).\n",
    "\n",
    "- **`batch_size`** *(Optional[int], default: None)*: The inference batch size. Must be ≥ 1. If specified, the generation is split into batches to optimize memory usage and save RAM.\n",
    "\n",
    "- **`random_seed`** *(Optional[int], default: None)*: A random seed for reproducible generation. Must be ≥ 0.\n",
    "\n",
    "- **`reports`** *(Union[str, Tuple[str], List[str]], default: \"none\")*: Controls generation of quality reports. Accepts single string or list of strings:\n",
    "  - `\"none\"` - no reports generated (default)\n",
    "  - `\"accuracy\"` - generates an accuracy report comparing original and synthetic data patterns to verify quality of a generated data\n",
    "  - `\"metrics_only\"` - outputs metrics to stdout without generating an accuracy report\n",
    "  - `\"all\"` - generates an accuracy report (same as `\"accuracy\"`)\n",
    "\n",
    "  List example: `[\"accuracy\", \"metrics_only\"]` to generate multiple report types\n",
    "\n",
    "  *Note*: Report generation may require significant time for large generated tables (>10,000 rows)\n",
    "\n",
    "- **`log_level`** *(str, default: \"INFO\")*: A logging level for the inference process. Accepted values: `\"TRACE\"`, `\"DEBUG\"`, `\"INFO\"`, `\"WARNING\"`, `\"ERROR\"`, `\"CRITICAL\"`.\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: A name of the environment variable containing a 44-character URL-safe base64-encoded Fernet key. When provided, the data subset is decrypted for a report generation. **Important**: The same key used during a training must be used during a report generation to successfully decrypt the data.\n",
    "\n",
    "\n",
    "*Note:* For full documentation, metadata file format, and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of inference for the single table\n",
    "\n",
    "launcher_for_single_table_with_source.infer(\n",
    "    size=100000,\n",
    "    run_parallel=False,\n",
    "    batch_size=5000,\n",
    "    random_seed=42,\n",
    "    reports=\"all\",\n",
    "    log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of inference for the single table\n",
    "\n",
    "launcher_for_single_table_with_loader.infer(\n",
    "    size=100000,\n",
    "    run_parallel=False,\n",
    "    batch_size=5000,\n",
    "    random_seed=42,\n",
    "    reports=\"all\",\n",
    "    log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of inference of multiple tables with relationships\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.infer(log_level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd28f7",
   "metadata": {},
   "source": [
    "The *'execution_artifacts'* attribute of the **Syngen** class provides information about the generated artifacts during the inference process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(launcher_for_multiple_tables.execution_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a6385",
   "metadata": {},
   "source": [
    "# Data security: Using Fernet key for encryption\n",
    "\n",
    "In the current implementation, a sample of the original data is stored on a disk during a training process. To ensure data security and protect sensitive information, you can use a **Fernet key** to encrypt this data.\n",
    "\n",
    "## What is a Fernet key?\n",
    "\n",
    "A Fernet key is a 44-character URL-safe base64-encoded string used for symmetric encryption. When provided, the data subset is encrypted on a disk (stored in the `.dat` format instead of unencrypted `.pkl` format).\n",
    "\n",
    "## How to generate a Fernet key\n",
    "\n",
    "You can generate a Fernet key using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cee26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Fernet key\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "fernet_key = Fernet.generate_key().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd259dc",
   "metadata": {},
   "source": [
    "## Setting the Fernet Key as an environment variable\n",
    "\n",
    "After generating the key, you need to store it as an environment variable. This can be done in your terminal or programmatically in Python.\n",
    "\n",
    "### Option 1: Set in Terminal (Linux/macOS)\n",
    "\n",
    "```bash\n",
    "export MY_FERNET_KEY='your_generated_fernet_key_here'\n",
    "```\n",
    "\n",
    "### Option 2: Set in Terminal (Windows)\n",
    "\n",
    "```cmd\n",
    "set MY_FERNET_KEY=your_generated_fernet_key_here\n",
    "```\n",
    "\n",
    "### Option 3: Set programmatically in Python\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ['MY_FERNET_KEY'] = 'your_generated_fernet_key_here'\n",
    "```\n",
    "\n",
    "## Using the Fernet Key in a training\n",
    "\n",
    "When training with encryption, pass the name of the environment variable (not the Fernet key itself) to the `fernet_key` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ece919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example: the training with the Fernet key encryption\n",
    "\n",
    "import os\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "# Step 1: Set the Fernet key as an environment variable\n",
    "os.environ[\"MY_FERNET_KEY\"] = fernet_key  # Using the key generated above\n",
    "\n",
    "# Step 2: Train with encryption enabled\n",
    "\n",
    "launcher_for_encrypted_data = Syngen(\n",
    "    source=\"../examples/example-data/housing.csv\", \n",
    "    table_name=\"housing_encrypted\"\n",
    ")\n",
    "\n",
    "launcher_for_encrypted_data.train(\n",
    "    epochs=5,\n",
    "    row_limit=1000, \n",
    "    batch_size=32, \n",
    "    fernet_key=\"MY_FERNET_KEY\"  # Pass the environment variable name, not the key itself\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed5c1b",
   "metadata": {},
   "source": [
    "## Using the Fernet Key in an inference\n",
    "\n",
    "**Important**: When generating synthetic data during an inference process, you must use the **same Fernet key** that was used during a training process. This allows the system to decrypt the stored data subset for a report generation.\n",
    "\n",
    "If the Fernet key is not provided or doesn't match the Fernet key used in the training process, the inference process will fail when trying to access the encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Inference with Fernet key decryption\n",
    "# The environment variable 'MY_FERNET_KEY' is already set from the training step\n",
    "\n",
    "# Inference with the same Fernet key\n",
    "\n",
    "\n",
    "launcher_for_encrypted_data.infer(\n",
    "    size=100000,\n",
    "    batch_size=5000, \n",
    "    random_seed=42,\n",
    "    reports=\"all\",\n",
    "    fernet_key=\"MY_FERNET_KEY\"  # Must use the same key as in a training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3232e8",
   "metadata": {},
   "source": [
    "## Using the Fernet Key with the metadata file\n",
    "\n",
    "You can also specify the Fernet key in the metadata file for both training and inference:\n",
    "\n",
    "```yaml\n",
    "global:\n",
    "  encryption:\n",
    "    fernet_key: MY_FERNET_KEY  # Name of the environment variable\n",
    "\n",
    "TABLE_NAME:\n",
    "  train_settings:\n",
    "    source: \"./data/table.csv\"\n",
    "  \n",
    "  infer_settings:\n",
    "    size: 100\n",
    "  \n",
    "  # You can also specify per-table encryption\n",
    "  encryption:\n",
    "    fernet_key: MY_FERNET_KEY\n",
    "```\n",
    "\n",
    "Then use it in your code:\n",
    "\n",
    "```python\n",
    "# Training with the metadata file and the Fernet key\n",
    "Syngen(metadata_path=\"path/to/metadata.yaml\").train()\n",
    "\n",
    "# Inference with the metadata file and the Fernet key\n",
    "Syngen(metadata_path=\"path/to/metadata.yaml\").infer()\n",
    "```\n",
    "\n",
    "## Important security notes\n",
    "\n",
    "⚠️ **Critical security considerations:**\n",
    "\n",
    "1. **Store the key securely**: Never hardcode the Fernet key directly in your code or commit it to version control systems.\n",
    "2. **Key recovery is impossible**: If you lose the Fernet key, encrypted data cannot be recovered\n",
    "3. **Same key required**: Always use the same Fernet key for a training, an inference and a report generation\n",
    "4. **Environment variable**: Use an environment variable to store the Fernet key securely\n",
    "5. **Key length**: The Fernet key must be exactly 44 characters (URL-safe base64-encoded)\n",
    "6. **Production environments**: In production, use secure secret management services (AWS Secrets Manager, Azure Key Vault, HashiCorp Vault, etc.)\n",
    "\n",
    "## What happens without a Fernet key?\n",
    "\n",
    "If you don't provide a `fernet_key` parameter:\n",
    "- Data subset is stored **unencrypted** in the `.pkl` format\n",
    "- No decryption is needed during the inference or the report generation\n",
    "- Suitable for non-sensitive data or development environments\n",
    "\n",
    "With a `fernet_key`:\n",
    "- Data subset is stored **encrypted** in the `.dat` format\n",
    "- Decryption is required during the inference or the report generation using the same Fernet key\n",
    "- Recommended for sensitive or production data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e90b1a",
   "metadata": {},
   "source": [
    "# Generate quality reports separately\n",
    "\n",
    "Sometimes you may want to generate quality reports separately after training or/and inference has already been completed to evaluate the quality of the input data or the generated data. The SDK provides the `Syngen().generate_quality_reports(...)` method that allows you to generate quality reports for a table using existing artifacts without re-running the training or/and inference processes.\n",
    "\n",
    "This method is useful when:\n",
    "- You completed training/inference without quality reports (with `reports=\"none\"`)\n",
    "- You want to generate additional report types later\n",
    "- You want to separate the computation-intensive training/inference from report generation\n",
    "\n",
    "\n",
    "```python\n",
    "generate_quality_reports(\n",
    "    self,\n",
    "    table_name: str,                        # required: the name of the table to generate quality reports for\n",
    "    reports: Union[str, Tuple[str], List[str]], # required: report types to generate\n",
    "    fernet_key: Optional[str] = None        # optional: a Fernet key for decrypting encrypted data\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters description:\n",
    "\n",
    "- **`table_name`** *(str, required)*: The name of the table to generate reports for.\n",
    "\n",
    "- **`reports`** *(Union[str, Tuple[str], List[str]], required)*: Controls which quality reports to generate. Accepts single string or list of strings:\n",
    "  - `\"accuracy\"` - generates an accuracy report comparing original and synthetic data\n",
    "  - `\"metrics_only\"` - outputs metrics information to stdout without generating an accuracy report\n",
    "  - `\"sample\"` - generates a sample report showing distribution comparisons between original data and the data subset used for a training process\n",
    "  - `\"all\"` - generates all available reports (*\"accuracy\"* and *\"sample\"*)\n",
    "  \n",
    "  List example: `[\"accuracy\", \"sample\"]` to generate multiple report types.\n",
    "\n",
    "  *Note*: Report generation may require significant time for large tables (>10,000 rows)\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: The name of the environment variable containing the Fernet key used to decrypt the original data subset. **Important**: Must be the same key used during training if the data was encrypted.\n",
    "\n",
    "### Required artifacts\n",
    "\n",
    "To generate quality reports, the following artifacts must exist:\n",
    "\n",
    "**For accuracy reports (`\"accuracy\"` or `\"metrics_only\"`):**\n",
    "- Training must be completed successfully\n",
    "- Inference must be completed successfully\n",
    "\n",
    "**For a `\"sample\"` report:**\n",
    "- Training must be completed successfully\n",
    "\n",
    "### Key notes:\n",
    "\n",
    "- The method uses existing artifacts and does not re-run a training or an inference process\n",
    "- All required artifacts must be present in the `model_artifacts` directory\n",
    "- The `table_name` must match exactly the name of the `table_name` that was used in a training/inference process\n",
    "- If data was encrypted during a training, the same `fernet_key` must be provided\n",
    "\n",
    "*Note:* For full documentation and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f71f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Generate an accuracy report after a training and inference process completed without a generation of quality reports.\n",
    "# Assume a training and inference process were already completed with reports=\"none\".\n",
    "# Now generate an accuracy report separately.\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_conditions\",\n",
    "    reports=\"accuracy\",\n",
    "    log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Generate a sample report after training completed\n",
    "\n",
    "# Generate a sample report to compare original data with its subset\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_properties\",\n",
    "    reports=\"sample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Generate multiple reports at once\n",
    "\n",
    "# Generate both accuracy and sample reports\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_conditions\",\n",
    "    reports=[\"accuracy\", \"sample\"]\n",
    ")\n",
    "\n",
    "# Or use \"all\" to generate all available reports\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_conditions\",\n",
    "    reports=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b32f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Generate quality reports for encrypted data\n",
    "import os\n",
    "\n",
    "# Ensure the Fernet key environment variable is set\n",
    "# (Should be the same key used during training)\n",
    "os.environ['MY_FERNET_KEY'] = fernet_key\n",
    "\n",
    "# Generate qulaity reports with decryption\n",
    "launcher_for_encrypted_data.generate_quality_reports(\n",
    "    table_name=\"housing_encrypted\",\n",
    "    reports=\"accuracy\",\n",
    "    fernet_key=\"MY_FERNET_KEY\"  # Same key used in training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed62d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Generate the \"metrics_only\" report (without a full accuracy report)\n",
    "# Output metrics to stdout\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing\",\n",
    "    reports=\"metrics_only\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b266f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "launcher_for_single_table_with_loader.generate_quality_reports(\n",
    "    table_name=\"housing\",\n",
    "    reports=\"sample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7862acd",
   "metadata": {},
   "source": [
    "# Using custom data loaders\n",
    "\n",
    "By providing the callback function to the `loader` allows you to load data from non-standard sources such as databases, APIs, Cloud storage, or any custom data source. This is particularly useful when:\n",
    "- Your data is stored in a database (PostgreSQL, MySQL, MongoDB, etc.)\n",
    "- You need to fetch data from an API or web service\n",
    "- Your data is in Cloud storage (AWS S3, Azure Blob Storage, Google Cloud Storage, etc.)\n",
    "- You need to apply custom preprocessing before a training/inference process\n",
    "- The file format is not directly supported\n",
    "\n",
    "## The requirements to the custom data loader\n",
    "\n",
    "A custom callback function provided to `loader` must meet these requirements:\n",
    "\n",
    "1. **Accept `table_name` as the first parameter** (str): The name of the table to load\n",
    "2. **Return a pandas DataFrame**: The loaded data must be returned as a pandas DataFrame\n",
    "\n",
    "## The callback function signature\n",
    "\n",
    "```python\n",
    "def custom_loader(table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data for the specified table.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name : str\n",
    "        The name of the table to load\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The loaded data as a pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Your loading logic here\n",
    "    return dataframe\n",
    "```\n",
    "\n",
    "## The example: the basic custom data loader\n",
    "```python\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_dataframe(table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    The demonstration of the callback function to load a CSV file,  \n",
    "    and get a pandas DataFrame from the 'example-data' directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name : str\n",
    "        The name of the table (the name of the file without extension) to load\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The loaded data as a pandas DataFrame\n",
    "    \"\"\"\n",
    "    path_to_example_data = f\"../examples/example-data/{table_name}.csv\"\n",
    "    \n",
    "    if not os.path.exists(path_to_example_data):\n",
    "        raise FileNotFoundError(f\"The CSV file '{table_name}.csv' does not exist\")\n",
    "    \n",
    "    return pd.read_csv(path_to_example_data)\n",
    "```\n",
    "\n",
    "## How to use the custom data loader\n",
    "\n",
    "### Step 1: Ensure the custom data loader function is importable\n",
    "\n",
    "Make sure your custom data loader function is importable.\n",
    "\n",
    "### Step 2: Provide the custom data loader function during the initialization of the class 'Syngen'\n",
    "\n",
    "```python\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "launcher = Syngen(loader=get_dataframe, table_name=\"housing\")\n",
    "\n",
    "launcher.train(\n",
    "    epochs=5,\n",
    "    row_limit=1000,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "launcher.infer(\n",
    "    size=10000,\n",
    "    batch_size=5000,\n",
    "    reports=\"accuracy\"\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05167a9e",
   "metadata": {},
   "source": [
    "# Data loading and saving: DataIO class\n",
    "\n",
    "The SDK provides the `DataIO` class for loading and saving data in various supported formats with optional encryption and format settings. This class is useful when you need to:\n",
    "- Load and save data in different file formats (*CSV*, *Avro*, *Excel*, etc.)\n",
    "- Load and save data with specific format settings\n",
    "- Work with encrypted data files\n",
    "\n",
    "## Class initialization\n",
    "\n",
    "```python\n",
    "DataIO(\n",
    "    path: str,                          # required: a path to the data file\n",
    "    fernet_key: Optional[str] = None,   # optional: a Fernet key for encrypted data\n",
    "    **kwargs                            # optional: format settings for CSV or Excel tables, or schema for AVRO file\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters description:\n",
    "\n",
    "- **`path`** *(str, required)*: the path to the data file to load or save. Supported formats include:\n",
    "  - CSV files: `.csv`, `.psv`, `.tsv`, `.txt`\n",
    "  - Avro files: `.avro`\n",
    "  - Excel files: `.xls`, `.xlsx`\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: the name of the environment variable containing the Fernet key for encrypted data operations.\n",
    "\n",
    "- **`**kwargs`**: Optional format settings or/and a schema for reading and writing data. Available parameters depend on the file format:\n",
    "\n",
    "  **For tables in '.csv', '.psv', '.tsv', '.txt' formats:**\n",
    "  - `sep` *(str)*: Delimiter to use (e.g., `','`, `';'`, `'\\t'`)\n",
    "  - `quotechar` *(str)*: Character used to denote the start and end of a quoted item (default: `'\"'`)\n",
    "  - `quoting` *(str)*: Quoting behavior - `\"all\"`, `\"minimal\"`, `\"non-numeric\"`, `\"none\"`\n",
    "  - `escapechar` *(str)*: Character used to escape other characters\n",
    "  - `encoding` *(str)*: Encoding to use (e.g., `'utf-8'`, `'latin-1'`)\n",
    "  - `header` *(Optional[int, List[int], Literal[\"infer\"]])*: Row number(s) containing column labels and marking the start of the data\n",
    "  - `skiprows` *(Optional[int, List[int]])*: Lines to skip at the start of the file\n",
    "  - `on_bad_lines` *(Literal[\"error\", \"warn\", \"skip\"])*: Action on bad lines - `\"error\"`, `\"warn\"`, `\"skip\"`\n",
    "  - `engine` *(Optional[Literal[\"c\", \"python\"]])*: Parser engine - `\"c\"`, `\"python\"`\n",
    "  - `na_values` *(Opional[List[str]])*: Additional strings to recognize as NA/NaN\n",
    "\n",
    "  **For Excel formats (.xls, .xlsx):**\n",
    "  - `sheet_name` *(Optional[str, int, List[Union[int, str]])*: Name or index of the sheet to read\n",
    "\n",
    "### Available methods\n",
    "\n",
    "`load_data(**kwargs)`\n",
    "\n",
    "Loads data from the specified file path and returns it as a pandas DataFrame.\n",
    "\n",
    "`load_schema()`\n",
    "\n",
    "Returns the original schema of the loaded data, including column names and data types. Available only for data in the *'.avro'* format.\n",
    "\n",
    "`save_data(df, **kwargs)`\n",
    "\n",
    "Saves a pandas DataFrame to the specified file path with(without) the configured format settings or schema.\n",
    "\n",
    "*Note:* For full documentation and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42612fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 1: Load CSV data with default settings\n",
    "\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "data_io = DataIO(path=\"../examples/example-data/housing.csv\")\n",
    "\n",
    "df = data_io.load_data()\n",
    "\n",
    "print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 2: Load CSV data with custom format settings\n",
    "\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "data_io = DataIO(\n",
    "    path=\"../examples/example-data/escaped_quoted_table.csv\",\n",
    "    sep=',',           # delimiter\n",
    "    quotechar='\"',     # quote character\n",
    "    quoting=\"minimal\", # quoting style\n",
    "    encoding='utf-8',  # encoding\n",
    "    header=0           # use first row as header\n",
    ")\n",
    "\n",
    "df = data_io.load_data()\n",
    "\n",
    "print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 3: Load data and get schema information\n",
    "\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "\n",
    "data_io = DataIO(path=\"../examples/example-data/avro_file.avro\")\n",
    "\n",
    "df = data_io.load_data()\n",
    "\n",
    "schema = data_io.load_schema()\n",
    "\n",
    "print(\"Data schema:\")\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 4: Save data to a file\n",
    "\n",
    "import pandas as pd\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'age': [25, 30, 35, 40, 45],\n",
    "    'city': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney']\n",
    "})\n",
    "\n",
    "\n",
    "data_io = DataIO(\n",
    "    path=\"../examples/example-data/sample_output.csv\",\n",
    "    sep=',',\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "\n",
    "data_io.save_data(sample_data)\n",
    "\n",
    "print(\"Data saved successfully to '../examples/example-data/sample_output.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
