{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5e143b",
   "metadata": {},
   "source": [
    "# Quick start\n",
    "\n",
    "*EPAM Syngen* is an unsupervised tabular data generation tool based on a variational autoencoder (VAE). \n",
    "It supports common tabular datatypes (floats, integers, datetime, text, categorical, binary) and can generate linked tables that sharing keys using the simple statistical approach. \n",
    "The SDK exposes simple programmatic entry points for training, inference, report generation, loading and saving data in supported formats - *CSV*, *Avro* and *Excel* format. The data should be located locally and be in UTF-8 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b1de2",
   "metadata": {},
   "source": [
    "This notebook demonstrates the SDK usage. Install the package and then you can call the main SDK class `Syngen` to run training, inference or generation of reports, and the class `DataIO` to load and save the data in supported formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe338621",
   "metadata": {},
   "source": [
    "Python *3.10* or *3.11* is required to run the library. The library is tested on Linux and Windows operating systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f88606",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "Please, install the library *syngen* (from Pypi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcbdea6c32caa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/, https://pypi.org/simple/\n",
      "Collecting syngen==0.10.33rc0\n",
      "  Downloading https://test-files.pythonhosted.org/packages/52/a6/9ff634fd9839f9bc7b1a2cc5f91ae63e864b0a18c4355c355d704bd7fb36/syngen-0.10.33rc0-py3-none-any.whl.metadata (45 kB)\n",
      "Collecting aiohttp>=3.10.11 (from syngen==0.10.33rc0)\n",
      "  Downloading aiohttp-3.13.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting attrs (from syngen==0.10.33rc0)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting avro (from syngen==0.10.33rc0)\n",
      "  Downloading avro-1.12.1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting base32-crockford (from syngen==0.10.33rc0)\n",
      "  Downloading base32_crockford-0.3.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting boto3 (from syngen==0.10.33rc0)\n",
      "  Downloading boto3-1.42.21-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting click (from syngen==0.10.33rc0)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cryptography (from syngen==0.10.33rc0)\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting Jinja2 (from syngen==0.10.33rc0)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting keras==2.15.* (from syngen==0.10.33rc0)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting lazy==1.4 (from syngen==0.10.33rc0)\n",
      "  Downloading lazy-1.4-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting loguru (from syngen==0.10.33rc0)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting MarkupSafe==2.1.1 (from syngen==0.10.33rc0)\n",
      "  Downloading MarkupSafe-2.1.1.tar.gz (18 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting marshmallow==3.19.* (from syngen==0.10.33rc0)\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting matplotlib==3.9.* (from syngen==0.10.33rc0)\n",
      "  Downloading matplotlib-3.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting mlflow==3.8.* (from syngen==0.10.33rc0)\n",
      "  Downloading https://test-files.pythonhosted.org/packages/ce/3d/d6cae3763024e85d21430903f75e54d337852bcdfda79470a5f5b178fc9f/mlflow-3.8.2-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting numpy==1.26.* (from syngen==0.10.33rc0)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting openpyxl (from syngen==0.10.33rc0)\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pandas==2.2.* (from syngen==0.10.33rc0)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pandavro==1.8.* (from syngen==0.10.33rc0)\n",
      "  Downloading pandavro-1.8.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pathos==0.2.* (from syngen==0.10.33rc0)\n",
      "  Downloading pathos-0.2.9-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pillow==10.3.* (from syngen==0.10.33rc0)\n",
      "  Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: psutil in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc0) (7.2.1)\n",
      "Collecting py-ulid (from syngen==0.10.33rc0)\n",
      "  Downloading py-ulid-1.0.3.tar.gz (5.4 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytest (from syngen==0.10.33rc0)\n",
      "  Downloading pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pytest-reportportal (from syngen==0.10.33rc0)\n",
      "  Downloading pytest_reportportal-5.6.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting python-slugify>=7.0.0 (from python-slugify[unidecode]>=7.0.0->syngen==0.10.33rc0)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting PyYAML==6.* (from syngen==0.10.33rc0)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting reportportal-client (from syngen==0.10.33rc0)\n",
      "  Downloading reportportal_client-5.7.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting scikit_learn==1.5.* (from syngen==0.10.33rc0)\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting scipy==1.14.* (from syngen==0.10.33rc0)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting seaborn==0.13.* (from syngen==0.10.33rc0)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting setuptools==78.1.* (from syngen==0.10.33rc0)\n",
      "  Downloading setuptools-78.1.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting tensorflow==2.15.* (from syngen==0.10.33rc0)\n",
      "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tornado==6.5.* in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from syngen==0.10.33rc0) (6.5.4)\n",
      "Collecting tqdm==4.66.3 (from syngen==0.10.33rc0)\n",
      "  Downloading tqdm-4.66.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting Werkzeug==3.1.* (from syngen==0.10.33rc0)\n",
      "  Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting xlrd (from syngen==0.10.33rc0)\n",
      "  Downloading xlrd-2.0.2-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting xlwt (from syngen==0.10.33rc0)\n",
      "  Downloading xlwt-1.3.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from marshmallow==3.19.*->syngen==0.10.33rc0) (25.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.9.*->syngen==0.10.33rc0)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.9.*->syngen==0.10.33rc0)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.9.*->syngen==0.10.33rc0)\n",
      "  Downloading fonttools-4.61.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.*->syngen==0.10.33rc0)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.*->syngen==0.10.33rc0)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from matplotlib==3.9.*->syngen==0.10.33rc0) (2.9.0.post0)\n",
      "Collecting mlflow-skinny==3.8.2 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading https://test-files.pythonhosted.org/packages/12/96/1cc89afe2f7d12c9e0581f117f0dfc7eb0b35d349c83c7c256b7c4fcab09/mlflow_skinny-3.8.2-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.8.2 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading https://test-files.pythonhosted.org/packages/75/2a/81d9f40683bc7ab31f57bc0dd0fd1b66e20385346a16f12e790d584ad745/mlflow_tracing-3.8.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting Flask<4 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting huey<3,>=2.5.0 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pyarrow<23,>=4.0.0 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading sqlalchemy-2.0.45-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading cachetools-6.2.4-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading databricks_sdk-0.76.0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading fastapi-0.128.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3,>=2.0.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting requests<3,>=2.17.3 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading sqlparse-0.5.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0) (4.15.0)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography->syngen==0.10.33rc0)\n",
      "  Downloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting urllib3>=1.26.0 (from docker<8,>=4.0.0->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas==2.2.*->syngen==0.10.33rc0)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.*->syngen==0.10.33rc0)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting fastavro<2.0.0,>=1.5.1 (from pandavro==1.8.*->syngen==0.10.33rc0)\n",
      "  Downloading fastavro-1.12.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting ppft>=1.7.6.5 (from pathos==0.2.*->syngen==0.10.33rc0)\n",
      "  Downloading ppft-1.7.7-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dill>=0.3.5.1 (from pathos==0.2.*->syngen==0.10.33rc0)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pox>=0.3.1 (from pathos==0.2.*->syngen==0.10.33rc0)\n",
      "  Downloading pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.13 (from pathos==0.2.*->syngen==0.10.33rc0)\n",
      "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.9.*->syngen==0.10.33rc0) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.17.3->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.17.3->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.17.3->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit_learn==1.5.*->syngen==0.10.33rc0)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit_learn==1.5.*->syngen==0.10.33rc0)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading greenlet-3.3.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=2.9.0 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading h5py-3.15.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow==2.15.* (from syngen==0.10.33rc0)\n",
      "  Downloading tensorflow-2.15.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow==2.15.* (from syngen==0.10.33rc0)\n",
      "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is still looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading opentelemetry_proto-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_proto-1.33.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_proto-1.32.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading google_auth_oauthlib-1.2.3-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.8.2->mlflow==3.8.*->syngen==0.10.33rc0)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10.11->syngen==0.10.33rc0)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp>=3.10.11->syngen==0.10.33rc0)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.10.11->syngen==0.10.33rc0)\n",
      "  Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10.11->syngen==0.10.33rc0)\n",
      "  Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.10.11->syngen==0.10.33rc0)\n",
      "  Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10.11->syngen==0.10.33rc0)\n",
      "  Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography->syngen==0.10.33rc0)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify>=7.0.0->python-slugify[unidecode]>=7.0.0->syngen==0.10.33rc0)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting Unidecode>=1.1.1 (from python-slugify[unidecode]>=7.0.0->syngen==0.10.33rc0)\n",
      "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.*->syngen==0.10.33rc0)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting botocore<1.43.0,>=1.42.21 (from boto3->syngen==0.10.33rc0)\n",
      "  Downloading botocore-1.42.21-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->syngen==0.10.33rc0)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3->syngen==0.10.33rc0)\n",
      "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting et-xmlfile (from openpyxl->syngen==0.10.33rc0)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting iniconfig>=1.0.1 (from pytest->syngen==0.10.33rc0)\n",
      "  Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest->syngen==0.10.33rc0)\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /home/Hanna_Imshenetska/pycharm/syngen/venv311local/lib/python3.11/site-packages (from pytest->syngen==0.10.33rc0) (2.19.2)\n",
      "Collecting aenum>=3.1.0 (from pytest-reportportal->syngen==0.10.33rc0)\n",
      "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Downloading https://test-files.pythonhosted.org/packages/52/a6/9ff634fd9839f9bc7b1a2cc5f91ae63e864b0a18c4355c355d704bd7fb36/syngen-0.10.33rc0-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lazy-1.4-py2.py3-none-any.whl (6.2 kB)\n",
      "Downloading tqdm-4.66.3-py3-none-any.whl (78 kB)\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m338.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "Downloading matplotlib-3.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m283.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://test-files.pythonhosted.org/packages/ce/3d/d6cae3763024e85d21430903f75e54d337852bcdfda79470a5f5b178fc9f/mlflow-3.8.2-py3-none-any.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m172.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://test-files.pythonhosted.org/packages/12/96/1cc89afe2f7d12c9e0581f117f0dfc7eb0b35d349c83c7c256b7c4fcab09/mlflow_skinny-3.8.2-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m228.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://test-files.pythonhosted.org/packages/75/2a/81d9f40683bc7ab31f57bc0dd0fd1b66e20385346a16f12e790d584ad745/mlflow_tracing-3.8.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m186.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "Downloading cachetools-6.2.4-py3-none-any.whl (11 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m644.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading databricks_sdk-0.76.0-py3-none-any.whl (774 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.7/774.7 kB\u001b[0m \u001b[31m677.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading fastapi-0.128.0-py3-none-any.whl (103 kB)\n",
      "Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
      "Downloading gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading huey-2.5.5-py3-none-any.whl (76 kB)\n",
      "Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m349.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m231.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m396.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m517.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m275.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandavro-1.8.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading fastavro-1.12.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m340.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathos-0.2.9-py3-none-any.whl (76 kB)\n",
      "Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m277.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m530.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m312.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m1.1 GB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m309.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m252.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading setuptools-78.1.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m551.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sqlalchemy-2.0.45-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m721.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlparse-0.5.5-py3-none-any.whl (46 kB)\n",
      "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m226.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.2.3-py3-none-any.whl (19 kB)\n",
      "Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m295.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
      "Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (77 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading aiohttp-3.13.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.0 GB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (215 kB)\n",
      "Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading fonttools-4.61.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m769.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading greenlet-3.3.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.2/590.2 kB\u001b[0m \u001b[31m919.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading h5py-3.15.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m285.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.0 GB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m283.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading multiprocess-0.70.18-py311-none-any.whl (144 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pox-0.3.6-py3-none-any.whl (29 kB)\n",
      "Downloading ppft-1.7.7-py3-none-any.whl (56 kB)\n",
      "Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m331.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading avro-1.12.1-py2.py3-none-any.whl (124 kB)\n",
      "Downloading base32_crockford-0.3.0-py2.py3-none-any.whl (5.0 kB)\n",
      "Downloading boto3-1.42.21-py3-none-any.whl (140 kB)\n",
      "Downloading botocore-1.42.21-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m642.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Downloading pytest-9.0.2-py3-none-any.whl (374 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading pytest_reportportal-5.6.0-py2.py3-none-any.whl (32 kB)\n",
      "Downloading reportportal_client-5.7.0-py2.py3-none-any.whl (81 kB)\n",
      "Downloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
      "Downloading xlrd-2.0.2-py2.py3-none-any.whl (96 kB)\n",
      "Downloading xlwt-1.3.0-py2.py3-none-any.whl (99 kB)\n",
      "Building wheels for collected packages: MarkupSafe, py-ulid\n",
      "  Building wheel for MarkupSafe (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for MarkupSafe: filename=markupsafe-2.1.1-cp311-cp311-linux_x86_64.whl size=27715 sha256=0448368dba559fde41703576c5cea8cacc3b2fff00e28e4d7a39eb052ae13efa\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z_1du3zs/wheels/f2/8e/9e/4ee907ff6fb9e145722f0506c46ad9516302d1f424b43220e5\n",
      "  Building wheel for py-ulid (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-ulid: filename=py_ulid-1.0.3-py3-none-any.whl size=5723 sha256=5cc8614c4c9d85e213e9a84a5bdf981a6c30eb8ddca58b4781bc97d658dbe01f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z_1du3zs/wheels/03/a0/20/af30ff40ed0de5e319bc285d059246e3b32f18b095688a9b95\n",
      "Successfully built MarkupSafe py-ulid\n",
      "Installing collected packages: xlwt, text-unidecode, pytz, py-ulid, libclang, lazy, huey, flatbuffers, base32-crockford, aenum, zipp, xlrd, wrapt, wheel, urllib3, Unidecode, tzdata, typing-inspection, tqdm, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, sqlparse, smmap, setuptools, PyYAML, python-slugify, python-dotenv, pyparsing, pydantic-core, pycparser, pyasn1, pyarrow, protobuf, propcache, ppft, pox, pluggy, pillow, opt-einsum, oauthlib, numpy, multidict, marshmallow, MarkupSafe, markdown, loguru, kiwisolver, keras, joblib, jmespath, itsdangerous, iniconfig, idna, h11, gunicorn, grpcio, greenlet, graphql-core, google-pasta, gast, frozenlist, fonttools, fastavro, et-xmlfile, dill, cycler, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, avro, attrs, annotated-types, annotated-doc, aiohappyeyeballs, absl-py, yarl, Werkzeug, uvicorn, sqlalchemy, scipy, rsa, requests, pytest, pydantic, pyasn1-modules, pandas, opentelemetry-proto, openpyxl, multiprocess, ml-dtypes, Mako, Jinja2, importlib_metadata, h5py, graphql-relay, gitdb, contourpy, cffi, botocore, astunparse, anyio, aiosignal, starlette, scikit_learn, s3transfer, requests-oauthlib, pathos, pandavro, opentelemetry-api, matplotlib, graphene, google-auth, gitpython, Flask, docker, cryptography, alembic, aiohttp, seaborn, reportportal-client, opentelemetry-semantic-conventions, google-auth-oauthlib, Flask-CORS, fastapi, databricks-sdk, boto3, tensorboard, pytest-reportportal, opentelemetry-sdk, tensorflow, mlflow-tracing, mlflow-skinny, mlflow, syngen\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/140\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K    Found existing installation: setuptools 65.5.0━━━━━━━━━━━━\u001b[0m \u001b[32m 23/140\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K    Uninstalling setuptools-65.5.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/140\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K      Successfully uninstalled setuptools-65.5.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 23/140\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140/140\u001b[0m [syngen] [syngen]skinny]w-tracing]dk]ventions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.2 Jinja2-3.1.6 Mako-1.3.10 MarkupSafe-2.1.1 PyYAML-6.0.3 Unidecode-1.4.0 Werkzeug-3.1.4 absl-py-2.3.1 aenum-3.1.16 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 alembic-1.17.2 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.0 astunparse-1.6.3 attrs-25.4.0 avro-1.12.1 base32-crockford-0.3.0 blinker-1.9.0 boto3-1.42.21 botocore-1.42.21 cachetools-6.2.4 certifi-2026.1.4 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-3.1.2 contourpy-1.3.3 cryptography-46.0.3 cycler-0.12.1 databricks-sdk-0.76.0 dill-0.4.0 docker-7.1.0 et-xmlfile-2.0.0 fastapi-0.128.0 fastavro-1.12.1 flatbuffers-25.12.19 fonttools-4.61.1 frozenlist-1.8.0 gast-0.7.0 gitdb-4.0.12 gitpython-3.1.46 google-auth-2.41.1 google-auth-oauthlib-1.2.3 google-pasta-0.2.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.3.0 grpcio-1.76.0 gunicorn-23.0.0 h11-0.16.0 h5py-3.15.1 huey-2.5.5 idna-3.11 importlib_metadata-8.7.1 iniconfig-2.3.0 itsdangerous-2.2.0 jmespath-1.0.1 joblib-1.5.3 keras-2.15.0 kiwisolver-1.4.9 lazy-1.4 libclang-18.1.1 loguru-0.7.3 markdown-3.10 marshmallow-3.19.0 matplotlib-3.9.4 ml-dtypes-0.3.2 mlflow-3.8.2 mlflow-skinny-3.8.2 mlflow-tracing-3.8.2 multidict-6.7.0 multiprocess-0.70.18 numpy-1.26.4 oauthlib-3.3.1 openpyxl-3.1.5 opentelemetry-api-1.39.1 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 opt-einsum-3.4.0 pandas-2.2.3 pandavro-1.8.0 pathos-0.2.9 pillow-10.3.0 pluggy-1.6.0 pox-0.3.6 ppft-1.7.7 propcache-0.4.1 protobuf-4.25.8 py-ulid-1.0.3 pyarrow-22.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.12.5 pydantic-core-2.41.5 pyparsing-3.3.1 pytest-9.0.2 pytest-reportportal-5.6.0 python-dotenv-1.2.1 python-slugify-8.0.4 pytz-2025.2 reportportal-client-5.7.0 requests-2.32.5 requests-oauthlib-2.0.0 rsa-4.9.1 s3transfer-0.16.0 scikit_learn-1.5.2 scipy-1.14.1 seaborn-0.13.2 setuptools-78.1.1 smmap-5.0.2 sqlalchemy-2.0.45 sqlparse-0.5.5 starlette-0.50.0 syngen-0.10.33rc0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.3.0 text-unidecode-1.3 threadpoolctl-3.6.0 tqdm-4.66.3 typing-inspection-0.4.2 tzdata-2025.3 urllib3-2.6.2 uvicorn-0.40.0 wheel-0.45.1 wrapt-1.14.2 xlrd-2.0.2 xlwt-1.3.0 yarl-1.22.0 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install  --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ --use-pep517 --no-cache-dir syngen==0.10.33rc0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3ce41",
   "metadata": {},
   "source": [
    "# Class initialization\n",
    "\n",
    "```python\n",
    "Syngen(\n",
    "    metadata_path: Optional[str] = None,  # use a metadata file in the '.yaml', '.yml' format for a training or an inference of one or multiple tables to centralize all parameters in one place\n",
    "    table_name: Optional[str] = None,     # required for a single-table training or inference process; an arbitrary string used to name the directories where artifacts are stored\n",
    "    source: Optional[str] = None,         # optional for a single-table training or inference process; a path to the file that you want to use as a reference\n",
    "    loader: Optional[Callable[[str], pd.DataFrame]] # optional for a training or inference process of one or multiple tables; a callback function that returns the sample of the original data of a certain table\n",
    ")\n",
    "```\n",
    "### Attributes description:\n",
    "\n",
    "- **`metadata_path`** *(Optional[str], default: None)*: a path to a metadata file in *'.yaml'* or *'.yml'* format, used during a training or inference processes to centralize all parameters for one or multiple tables in one place.\n",
    "- **`table_name`** *(Optional[str], default: None)*: a required parameter for a training or inference processes of a single table; an arbitrary string used to name the directories where artifacts are stored.\n",
    "- **`source`** *(Optional[str], default: None)*: an optional parameter for a single-table training or inference process; a path to the file that you want to use as a reference.\n",
    "- **`loader`** *(Optional[str], default: None)*: an optional parameter for a training or inference process of one or multiple tables; a callback function that returns the sample of the original data of a certain table.\n",
    "\n",
    "***Note***: You can provide the information about required attributes in one of three ways:\n",
    "1. Use `metadata_path` to define the a metadata of one or multiple tables and their relationships in one place.\n",
    "2. Using `table_name` and `source`: For a single-table training or inference process, provide both `table_name` and `source` if the original data is supplied directly from a `source`.\n",
    "3. Using `table_name` and `loader`: For a single-table training or inference process, provide both `table_name` and `loader` if the original data is supplied via a callback function (`loader`).\n",
    "4. Using `metadata_path` and `loader`: For a training or inference process of one or multiple tables if the original data of tables is supplied via a callback function (`loader`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6d2562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 13:51:37.278531: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-05 13:51:37.278570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-05 13:51:37.279502: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# The example of the initialization of the instance of the class 'Syngen' for the single-table training or inference process\n",
    "# by providing the `source` and 'table_name' parameters\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "\n",
    "launcher_for_single_table_with_source = Syngen(\n",
    "    source=\"../examples/example-data/housing.csv\", \n",
    "    table_name=\"housing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe83fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of the initialization of the instance of the class 'Syngen' for the single-table training or inference process \n",
    "# by providing the `loader` and 'table_name' parameters\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "\n",
    "\n",
    "def get_dataframe(table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    The demonstration callback function to load a CSV file \n",
    "    and get a pandas DataFrame from the 'example-data' directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name : str\n",
    "        The name of the table (CSV file without extension) to load\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The loaded data as a pandas DataFrame\n",
    "    \"\"\"\n",
    "    path_to_example_data = f\"../examples/example-data/{table_name}.csv\"\n",
    "    \n",
    "    if not os.path.exists(path_to_example_data):\n",
    "        raise FileNotFoundError(f\"The CSV file '{table_name}.csv' does not exist\")\n",
    "    \n",
    "    return pd.read_csv(path_to_example_data)\n",
    "\n",
    "\n",
    "\n",
    "launcher_for_single_table_with_loader = Syngen(\n",
    "    loader=get_dataframe, \n",
    "    table_name=\"housing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d8bb26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of the initialization of the instance of the class 'Syngen' for multiple tables\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables = Syngen(\n",
    "    metadata_path=\"../examples/example-metadata/housing_metadata.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1c86c",
   "metadata": {},
   "source": [
    "# Launch training\n",
    "\n",
    "You can start a training process using the SDK entrypoint `Syngen().train(...)`. This will train a model and save the model artifacts to a disk in the directory *'./model_artifacts'*. The SDK mirrors the CLI options so you can pass the same parameters programmatically. Below is a complete description of all available parameters:\n",
    "\n",
    "```python\n",
    "train(\n",
    "    self,\n",
    "    epochs: int = 10,                     # a number of training epochs\n",
    "    drop_null: bool = False,              # whether to drop rows with at least one missing value\n",
    "    row_limit: Optional[int] = None,      # a number of rows to train over\n",
    "    reports: Union[str, Tuple[str], List[str]] = \"none\",  # report types: \"none\", \"accuracy\", \"sample\", \"metrics_only\", \"all\"\n",
    "    log_level: Literal[\"TRACE\", \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"] = \"INFO\", # a logging level\n",
    "    batch_size: int = 32,                 # a training batch size\n",
    "    fernet_key: Optional[str] = None      # a name of the environment variable containing the Fernet key for secure storage of the data subset\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters description:\n",
    "\n",
    "- **`epochs`** *(int, default: 10)*: A number of training epochs. Must be ≥ 1. Since the early stopping mechanism is implemented the bigger value of epochs is the better.\n",
    "\n",
    "- **`drop_null`** *(bool, default: False)*: Whether to drop rows containing at least one missing value before training. When `False`, missing values are handled during the training process.\n",
    "\n",
    "- **`row_limit`** *(Optional[int], default: None)*: A maximum number of rows to use for training. If specified and less than the total rows, a random subset of the specified size will be selected. Useful for testing or working with large datasets.\n",
    "\n",
    "- **`reports`** *(Union[str, Tuple[str], List[str]], default: \"none\")*: Controls generation of quality reports. Accepts single string or list of strings:\n",
    "  - `\"none\"` - no reports generated (default)\n",
    "  - `\"accuracy\"` - generates an accuracy report comparing synthetic data (same size as original) with original dataset to estimate the quality of training process\n",
    "  - `\"sample\"` - generates a sample report showing distribution comparisons between the original data and the subset of this data\n",
    "  - `\"metrics_only\"` - outputs metrics to stdout without generation of an accuracy report\n",
    "  - `\"all\"` - generates both accuracy and sample reports\n",
    "\n",
    "  List example: `[\"accuracy\", \"sample\"]` to generate multiple report types\n",
    "\n",
    "  *Note*: Report generation may require significant time for large tables (>10,000 rows)\n",
    "\n",
    "- **`log_level`** *(str, default: \"INFO\")*: A logging level for the training process. Accepted values: `\"TRACE\"`, `\"DEBUG\"`, `\"INFO\"`, `\"WARNING\"`, `\"ERROR\"`, `\"CRITICAL\"`.\n",
    "\n",
    "- **`batch_size`** *(int, default: 32)*: A training batch size. Must be ≥ 1. Splits training into batches to optimize memory usage. Smaller batches use less RAM but may increase training time.\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: A name of the environment variable containing a 44-character URL-safe base64-encoded Fernet key. When provided, the data subset is encrypted on a disk (stored in the `.dat` format). If not provided, data is stored unencrypted in the `.pkl` format. **Important**: The same key must be used during an inference and a report generation to decrypt the data.\n",
    "\n",
    "\n",
    "*Note:* For full documentation, metadata file format, and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e1a8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 13:58:26.039\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.validation_schema.validation_schema\u001b[0m:\u001b[36mvalidate_schema\u001b[0m:\u001b[36m348\u001b[0m - \u001b[34m\u001b[1mThe schema of the metadata is valid\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_collect_errors\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mThe validation of the metadata has been passed successfully\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.045\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcheck_mlflow_server\u001b[0m:\u001b[36m32\u001b[0m - \u001b[33m\u001b[1mMLFlow server URL not provided\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.045\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcreate_tracker\u001b[0m:\u001b[36m69\u001b[0m - \u001b[33m\u001b[1mMLFlow server is either unreachable or not set up, therefore the tracking will not be performed\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.train\u001b[0m:\u001b[36mlaunch_train\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe training process will be executed according to the information mentioned in 'train_settings' in the metadata file. If appropriate information is absent from the metadata file, then the values of parameters sent through CLI will be used. Otherwise, the values of parameters will be defaulted.\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.processors.processors\u001b[0m:\u001b[36m_preprocess_data\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mThe subset of rows was set to 1000\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_train_table\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mTraining process of the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mStart VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_pk_key\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mNo primary key was set.\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_uq_keys\u001b[0m:\u001b[36m267\u001b[0m - \u001b[1mNo unique keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_fk_keys\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mNo foreign keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.139\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_detection_pipeline\u001b[0m:\u001b[36m1081\u001b[0m - \u001b[34m\u001b[1mCount of string columns: 0; Count of email columns: 0; Count of float columns: 3; Count of int columns: 6; Count of categorical columns: 1; Count of date columns: 0; Count of binary columns: 0; Count of long text columns: 0; Count of uuid columns: 0\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'longitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'latitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'housing_median_age' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_rooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_preprocess_nan_cols\u001b[0m:\u001b[36m1206\u001b[0m - \u001b[1mColumn 'total_bedrooms' contains 8 (0.8%) empty values out of 1000. Filling them with mean.\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_bedrooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mColumn 'total_bedrooms_null' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'population' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'households' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'median_income' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'median_house_value' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_categ_feature\u001b[0m:\u001b[36m1392\u001b[0m - \u001b[1mColumn 'ocean_proximity' assigned as categorical based feature.\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:26.713\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m178\u001b[0m - \u001b[34m\u001b[1mTrain model with parameters: epochs=5, row_subset=1000, drop_null=False, batch_size=100, reports - 'accuracy', 'sample'\u001b[0m\n",
      "10it [00:01,  7.81it/s]\n",
      "\u001b[32m2026-01-05 13:58:28.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 0, total loss: 2.816272020339966, time: 1.3546 sec\u001b[0m\n",
      "10it [00:00, 10.06it/s]\n",
      "\u001b[32m2026-01-05 13:58:29.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 1, total loss: 2.380002975463867, time: 1.0296 sec\u001b[0m\n",
      "10it [00:00, 10.09it/s]\n",
      "\u001b[32m2026-01-05 13:58:30.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 2, total loss: 2.2522642612457275, time: 1.0228 sec\u001b[0m\n",
      "10it [00:00, 10.14it/s]\n",
      "\u001b[32m2026-01-05 13:58:31.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 3, total loss: 1.9947912693023682, time: 1.0210 sec\u001b[0m\n",
      "10it [00:00, 10.19it/s]\n",
      "\u001b[32m2026-01-05 13:58:32.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 4, total loss: 1.7371668815612793, time: 1.0128 sec\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:32.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFit sampler\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:32.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mStart encoding\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 750us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 13:58:32.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m187\u001b[0m - \u001b[1mCreating BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:32.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mFitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:34.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished fitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:34.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36msave_state\u001b[0m:\u001b[36m545\u001b[0m - \u001b[1mSaved VAE state in model_artifacts/resources/housing/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:34.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:34.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mNo columns to train kde over found\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:34.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mTraining of the table - 'housing' was completed\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:34.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m520\u001b[0m - \u001b[1mInfer process of the table - 'housing' has started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/32 [..............................] - ETA: 4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 13:58:35.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36mload_state\u001b[0m:\u001b[36m554\u001b[0m - \u001b[1mLoaded VAE state from model_artifacts/resources/housing/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:35.228\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m490\u001b[0m - \u001b[34m\u001b[1mInfer model with parameters: size=1000, run_parallel=False, batch_size=1000, random_seed=1\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:35.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mTotal of 1 batch(es)\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:35.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 1 of 1\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:35.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:35.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 7882.68it/s]\n",
      "\u001b[32m2026-01-05 13:58:35.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:35.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mSynthesis of the table - 'housing' was completed. Synthetic data saved in 'model_artifacts/tmp_store/housing/merged_infer_housing.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:35.510\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36mgenerate_report\u001b[0m:\u001b[36m241\u001b[0m - \u001b[33m\u001b[1mThe report(s) generation might be time-consuming\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:35.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of sample metrics for the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:38.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe sample report of the table - 'housing' has been generated\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:38.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:39.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.8117\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 45/45 [00:16<00:00,  2.76it/s]\n",
      "\u001b[32m2026-01-05 13:58:57.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0.2466\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:58.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.0033\u001b[0m\n",
      "\u001b[32m2026-01-05 13:58:58.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 9/9 [00:01<00:00,  7.10it/s]\n",
      "\u001b[32m2026-01-05 13:59:00.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1498\u001b[0m - \u001b[1mThe ratio of synthetic multiclass accuracy to original is 0.5413. The model considers the 'ocean_proximity' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 13:59:00.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'households' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 13:59:00.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 13:59:00.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing' has been generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The example of a training the single table on the provided data fetching it via the 'source' parameter\n",
    "\n",
    "\n",
    "launcher_for_single_table_with_source.train(\n",
    "    epochs=5,\n",
    "    drop_null=False,\n",
    "    row_limit=1000, \n",
    "    batch_size=100,\n",
    "    reports=\"all\",\n",
    "    log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "925f2ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:05:31.215\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.validation_schema.validation_schema\u001b[0m:\u001b[36mvalidate_schema\u001b[0m:\u001b[36m348\u001b[0m - \u001b[34m\u001b[1mThe schema of the metadata is valid\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/resources/housing/' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_collect_errors\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mThe validation of the metadata has been passed successfully\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.222\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcheck_mlflow_server\u001b[0m:\u001b[36m32\u001b[0m - \u001b[33m\u001b[1mMLFlow server URL not provided\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.222\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcreate_tracker\u001b[0m:\u001b[36m69\u001b[0m - \u001b[33m\u001b[1mMLFlow server is either unreachable or not set up, therefore the tracking will not be performed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.train\u001b[0m:\u001b[36mlaunch_train\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe training process will be executed according to the information mentioned in 'train_settings' in the metadata file. If appropriate information is absent from the metadata file, then the values of parameters sent through CLI will be used. Otherwise, the values of parameters will be defaulted.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.data_loaders.dataframe_fetcher\u001b[0m:\u001b[36mfetch_data\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mSuccessfully fetched dataframe for table: housing\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.processors.processors\u001b[0m:\u001b[36m_preprocess_data\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mThe subset of rows was set to 1000\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_train_table\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mTraining process of the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mStart VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_pk_key\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mNo primary key was set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_uq_keys\u001b[0m:\u001b[36m267\u001b[0m - \u001b[1mNo unique keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_fk_keys\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mNo foreign keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.252\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_detection_pipeline\u001b[0m:\u001b[36m1081\u001b[0m - \u001b[34m\u001b[1mCount of string columns: 0; Count of email columns: 0; Count of float columns: 3; Count of int columns: 6; Count of categorical columns: 1; Count of date columns: 0; Count of binary columns: 0; Count of long text columns: 0; Count of uuid columns: 0\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'longitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'latitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'housing_median_age' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_rooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_preprocess_nan_cols\u001b[0m:\u001b[36m1206\u001b[0m - \u001b[1mColumn 'total_bedrooms' contains 9 (0.9%) empty values out of 1000. Filling them with mean.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_bedrooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mColumn 'total_bedrooms_null' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'population' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'households' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'median_income' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'median_house_value' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_categ_feature\u001b[0m:\u001b[36m1392\u001b[0m - \u001b[1mColumn 'ocean_proximity' assigned as categorical based feature.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:31.700\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m178\u001b[0m - \u001b[34m\u001b[1mTrain model with parameters: epochs=5, row_subset=1000, drop_null=False, batch_size=100, reports - 'accuracy', 'sample'\u001b[0m\n",
      "10it [00:01,  9.46it/s]\n",
      "\u001b[32m2026-01-05 14:05:32.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 0, total loss: 2.7722885608673096, time: 1.1003 sec\u001b[0m\n",
      "10it [00:01,  9.79it/s]\n",
      "\u001b[32m2026-01-05 14:05:33.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 1, total loss: 2.2187585830688477, time: 1.0540 sec\u001b[0m\n",
      "10it [00:01,  9.67it/s]\n",
      "\u001b[32m2026-01-05 14:05:34.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 2, total loss: 2.0282089710235596, time: 1.0670 sec\u001b[0m\n",
      "10it [00:01,  9.71it/s]\n",
      "\u001b[32m2026-01-05 14:05:36.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 3, total loss: 1.872093915939331, time: 1.0610 sec\u001b[0m\n",
      "10it [00:01,  9.85it/s]\n",
      "\u001b[32m2026-01-05 14:05:37.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 4, total loss: 1.7618767023086548, time: 1.0466 sec\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:37.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFit sampler\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:37.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mStart encoding\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 773us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:05:37.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m187\u001b[0m - \u001b[1mCreating BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:37.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mFitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished fitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36msave_state\u001b[0m:\u001b[36m545\u001b[0m - \u001b[1mSaved VAE state in model_artifacts/resources/housing/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mNo columns to train kde over found\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mTraining of the table - 'housing' was completed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m520\u001b[0m - \u001b[1mInfer process of the table - 'housing' has started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/32 [..............................] - ETA: 4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:05:39.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36mload_state\u001b[0m:\u001b[36m554\u001b[0m - \u001b[1mLoaded VAE state from model_artifacts/resources/housing/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.693\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m490\u001b[0m - \u001b[34m\u001b[1mInfer model with parameters: size=1000, run_parallel=False, batch_size=1000, random_seed=1\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mTotal of 1 batch(es)\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 1 of 1\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 8929.23it/s]\n",
      "\u001b[32m2026-01-05 14:05:39.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mSynthesis of the table - 'housing' was completed. Synthetic data saved in 'model_artifacts/tmp_store/housing/merged_infer_housing.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.962\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36mgenerate_report\u001b[0m:\u001b[36m241\u001b[0m - \u001b[33m\u001b[1mThe report(s) generation might be time-consuming\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of sample metrics for the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.data_loaders.dataframe_fetcher\u001b[0m:\u001b[36mfetch_data\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mSuccessfully fetched dataframe for table: housing\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:39.978\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_fetch_dataframe\u001b[0m:\u001b[36m64\u001b[0m - \u001b[33m\u001b[1mThe original data of the table - 'housing' has been fetched using the callback function. The data may have been modified since the beginning of the training process.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:44.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe sample report of the table - 'housing' has been generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:44.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:05:44.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.8511\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 45/45 [00:16<00:00,  2.73it/s]\n",
      "\u001b[32m2026-01-05 14:06:03.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0.1659\u001b[0m\n",
      "\u001b[32m2026-01-05 14:06:04.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.0028\u001b[0m\n",
      "\u001b[32m2026-01-05 14:06:04.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s]\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 9/9 [00:01<00:00,  7.18it/s]\n",
      "\u001b[32m2026-01-05 14:06:05.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1498\u001b[0m - \u001b[1mThe ratio of synthetic multiclass accuracy to original is 0.538. The model considers the 'ocean_proximity' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:06:05.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'households' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:06:05.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:06:05.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing' has been generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The example of training the single table on the provided data fetching it via the 'loader' parameter\n",
    "\n",
    "\n",
    "launcher_for_single_table_with_loader.train(\n",
    "    epochs=5,\n",
    "    drop_null=False,\n",
    "    row_limit=1000, \n",
    "    batch_size=100, \n",
    "    reports=\"all\",\n",
    "    log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebe2a35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'housing': {'losses_path': 'model_artifacts/system_store/losses/losses-housing-2026-01-05-14-05-31-243731.csv',\n",
       "  'path_to_input_data': 'model_artifacts/tmp_store/housing/input_data_housing.pkl',\n",
       "  'generated_reports': {'sample_report': 'model_artifacts/resources/housing/reports/sample-report-2026_01_05_14_05_44_070491.html',\n",
       "   'accuracy_report': 'model_artifacts/resources/housing/reports/accuracy-report-2026_01_05_14_06_05_805637.html'}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launcher_for_single_table_with_loader.execution_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "652f378a17c58f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:01:03.815\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.validation_schema.validation_schema\u001b[0m:\u001b[36mvalidate_schema\u001b[0m:\u001b[36m348\u001b[0m - \u001b[34m\u001b[1mThe schema of the metadata is valid\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/resources/housing-properties/' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_collect_errors\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mThe validation of the metadata has been passed successfully\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.820\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcheck_mlflow_server\u001b[0m:\u001b[36m32\u001b[0m - \u001b[33m\u001b[1mMLFlow server URL not provided\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.820\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcreate_tracker\u001b[0m:\u001b[36m69\u001b[0m - \u001b[33m\u001b[1mMLFlow server is either unreachable or not set up, therefore the tracking will not be performed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.train\u001b[0m:\u001b[36mlaunch_train\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe training process will be executed according to the information mentioned in 'train_settings' in the metadata file. If appropriate information is absent from the metadata file, then the values of parameters sent through CLI will be used. Otherwise, the values of parameters will be defaulted.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.processors.processors\u001b[0m:\u001b[36m_preprocess_data\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mThe subset of rows was set to 790\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_train_table\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mTraining process of the table - 'housing_properties' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mStart VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_pk_key\u001b[0m:\u001b[36m212\u001b[0m - \u001b[1mThe primary key name was set: households_pk\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_validate_pk_key\u001b[0m:\u001b[36m244\u001b[0m - \u001b[1mValues in primary key are unique.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_uq_keys\u001b[0m:\u001b[36m267\u001b[0m - \u001b[1mNo unique keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_fk_keys\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mNo foreign keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.841\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_detection_pipeline\u001b[0m:\u001b[36m1081\u001b[0m - \u001b[34m\u001b[1mCount of string columns: 0; Count of email columns: 0; Count of float columns: 3; Count of int columns: 3; Count of categorical columns: 1; Count of date columns: 0; Count of binary columns: 0; Count of long text columns: 0; Count of uuid columns: 0\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'longitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'latitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'population' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'households' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'median_income' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'median_house_value' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:03.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_categ_feature\u001b[0m:\u001b[36m1392\u001b[0m - \u001b[1mColumn 'ocean_proximity' assigned as categorical based feature.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:04.168\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m178\u001b[0m - \u001b[34m\u001b[1mTrain model with parameters: epochs=8, row_subset=790, drop_null=True, batch_size=32, reports - 'accuracy', 'sample'\u001b[0m\n",
      "24it [00:01, 12.88it/s]\n",
      "\u001b[32m2026-01-05 14:01:06.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 0, total loss: 2.253485679626465, time: 1.8959 sec\u001b[0m\n",
      "24it [00:01, 13.27it/s]\n",
      "\u001b[32m2026-01-05 14:01:07.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 1, total loss: 1.883497953414917, time: 1.8366 sec\u001b[0m\n",
      "24it [00:01, 13.30it/s]\n",
      "\u001b[32m2026-01-05 14:01:09.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 2, total loss: 1.6160337924957275, time: 1.8313 sec\u001b[0m\n",
      "24it [00:01, 13.30it/s]\n",
      "\u001b[32m2026-01-05 14:01:11.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 3, total loss: 1.471489429473877, time: 1.8312 sec\u001b[0m\n",
      "24it [00:01, 13.26it/s]\n",
      "\u001b[32m2026-01-05 14:01:13.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 4, total loss: 1.3323780298233032, time: 1.8375 sec\u001b[0m\n",
      "24it [00:01, 13.27it/s]\n",
      "\u001b[32m2026-01-05 14:01:15.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 5, total loss: 1.198582410812378, time: 1.8345 sec\u001b[0m\n",
      "24it [00:01, 13.08it/s]\n",
      "\u001b[32m2026-01-05 14:01:17.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 6, total loss: 1.0079597234725952, time: 1.8608 sec\u001b[0m\n",
      "24it [00:01, 13.30it/s]\n",
      "\u001b[32m2026-01-05 14:01:18.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 7, total loss: 0.9343766570091248, time: 1.8302 sec\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:18.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFit sampler\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:18.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mStart encoding\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 865us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:01:19.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m187\u001b[0m - \u001b[1mCreating BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:19.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mFitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished fitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36msave_state\u001b[0m:\u001b[36m545\u001b[0m - \u001b[1mSaved VAE state in model_artifacts/resources/housing-properties/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mNo columns to train kde over found\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mTraining of the table - 'housing_properties' was completed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.processors.processors\u001b[0m:\u001b[36m_preprocess_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mAs the parameter 'drop_null' set to 'True', 16 rows of the table - 'housing_conditions' that have empty values have been dropped. The count of remained rows is 1799.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.processors.processors\u001b[0m:\u001b[36m_preprocess_data\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mThe subset of rows was set to 1799\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_train_table\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mTraining process of the table - 'housing_conditions' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mStart VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_pk_key\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mNo primary key was set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_uq_keys\u001b[0m:\u001b[36m267\u001b[0m - \u001b[1mNo unique keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_fk_keys\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mThe following foreign keys were set: households_fk\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_fetch_categorical_columns\u001b[0m:\u001b[36m518\u001b[0m - \u001b[1mThe columns - housing_median_age were defined as categorical due to the information from the metadata of the table - 'housing_conditions'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.236\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_detection_pipeline\u001b[0m:\u001b[36m1081\u001b[0m - \u001b[34m\u001b[1mCount of string columns: 0; Count of email columns: 0; Count of float columns: 0; Count of int columns: 3; Count of categorical columns: 1; Count of date columns: 0; Count of binary columns: 0; Count of long text columns: 0; Count of uuid columns: 0\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_save_kde_artifacts\u001b[0m:\u001b[36m1273\u001b[0m - \u001b[1mKDE artifacts saved to model_artifacts/resources/housing-conditions/vae/checkpoints/stat_keys/households.pkl\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.238\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_drop_fk_columns\u001b[0m:\u001b[36m1305\u001b[0m - \u001b[34m\u001b[1mThe column - 'households' dropped from the training process as it is defined as FK column and will be sampled from the PK table\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_categ_feature\u001b[0m:\u001b[36m1392\u001b[0m - \u001b[1mColumn 'housing_median_age' assigned as categorical based feature.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_rooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_bedrooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:20.457\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m178\u001b[0m - \u001b[34m\u001b[1mTrain model with parameters: epochs=5, row_subset=1799, drop_null=True, batch_size=32, reports - 'accuracy', 'sample'\u001b[0m\n",
      "56it [00:03, 18.29it/s]\n",
      "\u001b[32m2026-01-05 14:01:23.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 0, total loss: 3.9785702228546143, time: 3.0954 sec\u001b[0m\n",
      "56it [00:03, 18.29it/s]\n",
      "\u001b[32m2026-01-05 14:01:26.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 1, total loss: 3.9256584644317627, time: 3.0814 sec\u001b[0m\n",
      "56it [00:03, 18.40it/s]\n",
      "\u001b[32m2026-01-05 14:01:29.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 2, total loss: 3.875135898590088, time: 3.0645 sec\u001b[0m\n",
      "56it [00:03, 18.54it/s]\n",
      "\u001b[32m2026-01-05 14:01:32.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 3, total loss: 3.7052714824676514, time: 3.0413 sec\u001b[0m\n",
      "56it [00:02, 18.76it/s]\n",
      "\u001b[32m2026-01-05 14:01:35.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 4, total loss: 3.420416831970215, time: 3.0065 sec\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:35.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFit sampler\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:35.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mStart encoding\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 748us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:01:35.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m187\u001b[0m - \u001b[1mCreating BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:35.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mFitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished fitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36msave_state\u001b[0m:\u001b[36m545\u001b[0m - \u001b[1mSaved VAE state in model_artifacts/resources/housing-conditions/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mNo columns to train kde over found\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mTraining of the table - 'housing_conditions' was completed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m520\u001b[0m - \u001b[1mInfer process of the table - 'housing_properties' has started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:01:37.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36mload_state\u001b[0m:\u001b[36m554\u001b[0m - \u001b[1mLoaded VAE state from model_artifacts/resources/housing-properties/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.634\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m490\u001b[0m - \u001b[34m\u001b[1mInfer model with parameters: size=790, run_parallel=False, batch_size=790, random_seed=1\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mTotal of 1 batch(es)\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_properties'. Generating the batch 1 of 1\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_properties' started.\u001b[0m\n",
      "Generation of the data...: 100%|██████████| 7/7 [00:00<00:00, 6810.51it/s]\n",
      "\u001b[32m2026-01-05 14:01:37.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mSynthesis of the table - 'housing_properties' was completed. Synthetic data saved in 'model_artifacts/tmp_store/housing-properties/merged_infer_housing-properties.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:37.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m520\u001b[0m - \u001b[1mInfer process of the table - 'housing_conditions' has started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 958us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:01:38.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36mload_state\u001b[0m:\u001b[36m554\u001b[0m - \u001b[1mLoaded VAE state from model_artifacts/resources/housing-conditions/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.043\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m490\u001b[0m - \u001b[34m\u001b[1mInfer model with parameters: size=1799, run_parallel=False, batch_size=1000, random_seed=1\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mTotal of 2 batch(es)\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_conditions'. Generating the batch 1 of 2\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_conditions' started.\u001b[0m\n",
      "Generation of the data...: 100%|██████████| 3/3 [00:00<00:00, 3918.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/25 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:01:38.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_conditions'. Generating the batch 2 of 2\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_conditions' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 3/3 [00:00<00:00, 3974.39it/s]\n",
      "\u001b[32m2026-01-05 14:01:38.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mgenerate_keys\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mThe 'households' assigned as a foreign_key feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mSynthesis of the table - 'housing_conditions' was completed. Synthetic data saved in 'model_artifacts/tmp_store/housing-conditions/merged_infer_housing-conditions.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.303\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36mgenerate_report\u001b[0m:\u001b[36m241\u001b[0m - \u001b[33m\u001b[1mThe report(s) generation might be time-consuming\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:38.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of sample metrics for the table - 'housing_conditions' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:39.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe sample report of the table - 'housing_conditions' has been generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:39.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing_conditions' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:39.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.8057\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]\n",
      "\u001b[32m2026-01-05 14:01:42.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:43.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.9846\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:43.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
      "\u001b[32m2026-01-05 14:01:43.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36m__model_process\u001b[0m:\u001b[36m1583\u001b[0m - \u001b[1mThe best score for all possible multiclass classification models for the original data is 0.0611, which is below 0.6. The utility metric is unreliable\u001b[0m\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 2/2 [00:00<00:00,  6.81it/s]\n",
      "\u001b[32m2026-01-05 14:01:43.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1498\u001b[0m - \u001b[1mThe ratio of synthetic multiclass accuracy to original is 5.3575. The model considers the 'housing_median_age' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:43.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'total_rooms' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:43.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:43.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing_conditions' has been generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:43.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of sample metrics for the table - 'housing_properties' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:44.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe sample report of the table - 'housing_properties' has been generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:44.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing_properties' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:45.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.7902\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 15/15 [00:05<00:00,  2.75it/s]\n",
      "\u001b[32m2026-01-05 14:01:52.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:52.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.3544\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:52.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 5/5 [00:00<00:00,  7.12it/s]\n",
      "\u001b[32m2026-01-05 14:01:53.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1498\u001b[0m - \u001b[1mThe ratio of synthetic multiclass accuracy to original is 0.7325. The model considers the 'ocean_proximity' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:53.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'longitude' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:53.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:01:53.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing_properties' has been generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The example of training of multiple tables with relationships\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.train(log_level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18988c75",
   "metadata": {},
   "source": [
    "The *'execution_artifacts'* attribute of the **Syngen** class provides information about the generated artifacts during the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19f0346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'housing_conditions': {'generated_reports': {'accuracy_report': 'model_artifacts/resources/housing-conditions/reports/accuracy-report-2026_01_05_14_01_43_779222.html',\n",
      "                                              'sample_report': 'model_artifacts/resources/housing-conditions/reports/sample-report-2026_01_05_14_01_39_128961.html'},\n",
      "                        'losses_path': 'model_artifacts/system_store/losses/losses-housing-conditions-2026-01-05-14-01-20-232256.csv',\n",
      "                        'path_to_input_data': 'model_artifacts/tmp_store/housing-conditions/input_data_housing-conditions.pkl'},\n",
      " 'housing_properties': {'generated_reports': {'accuracy_report': 'model_artifacts/resources/housing-properties/reports/accuracy-report-2026_01_05_14_01_53_397026.html',\n",
      "                                              'sample_report': 'model_artifacts/resources/housing-properties/reports/sample-report-2026_01_05_14_01_44_986258.html'},\n",
      "                        'losses_path': 'model_artifacts/system_store/losses/losses-housing-properties-2026-01-05-14-01-03-832485.csv',\n",
      "                        'path_to_input_data': 'model_artifacts/tmp_store/housing-properties/input_data_housing-properties.pkl'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(launcher_for_multiple_tables.execution_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf34c2c",
   "metadata": {},
   "source": [
    "# Launch generation of synthetic data\n",
    "\n",
    "You can start an inference process using the SDK entrypoint `Syngen().infer(...)`. The SDK mirrors the CLI options so you can pass the same parameters programmatically. Below is a complete description of all available parameters:\n",
    "\n",
    "```python\n",
    "infer(\n",
    "    self,\n",
    "    size: int = 100,                      # the desired number of rows to generate\n",
    "    run_parallel: bool = False,           # whether to use multiprocessing (feasible for tables > 50000 rows)\n",
    "    batch_size: Optional[int] = None,     # an inference batch size\n",
    "    random_seed: Optional[int] = None,    # if specified, generates a reproducible result\n",
    "    reports: Union[str, List[str]] = \"none\",  # report types: \"none\", \"accuracy\", \"metrics_only\", \"all\"\n",
    "    log_level: str = \"INFO\",              # a logging level\n",
    "    fernet_key: Optional[str] = None      # a name of the environment variable containing the Fernet key for decrypting the data subset\n",
    ")\n",
    "```\n",
    "### Parameters description:\n",
    "\n",
    "- **`size`** *(int, default: 100)*: The desired number of synthetic rows to generate. Must be ≥ 1.\n",
    "\n",
    "- **`run_parallel`** *(bool, default: False)*: Whether to use multiprocessing for data generation. Set to `True` to enable parallel processing, which is recommended and feasible for generating large tables (> 50000 rows).\n",
    "\n",
    "- **`batch_size`** *(Optional[int], default: None)*: The inference batch size. Must be ≥ 1. If specified, the generation is split into batches to optimize memory usage and save RAM.\n",
    "\n",
    "- **`random_seed`** *(Optional[int], default: None)*: A random seed for reproducible generation. Must be ≥ 0.\n",
    "\n",
    "- **`reports`** *(Union[str, Tuple[str], List[str]], default: \"none\")*: Controls generation of quality reports. Accepts single string or list of strings:\n",
    "  - `\"none\"` - no reports generated (default)\n",
    "  - `\"accuracy\"` - generates an accuracy report comparing original and synthetic data patterns to verify quality of a generated data\n",
    "  - `\"metrics_only\"` - outputs metrics to stdout without generating an accuracy report\n",
    "  - `\"all\"` - generates an accuracy report (same as `\"accuracy\"`)\n",
    "\n",
    "  List example: `[\"accuracy\", \"metrics_only\"]` to generate multiple report types\n",
    "\n",
    "  *Note*: Report generation may require significant time for large generated tables (>10,000 rows)\n",
    "\n",
    "- **`log_level`** *(str, default: \"INFO\")*: A logging level for the inference process. Accepted values: `\"TRACE\"`, `\"DEBUG\"`, `\"INFO\"`, `\"WARNING\"`, `\"ERROR\"`, `\"CRITICAL\"`.\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: A name of the environment variable containing a 44-character URL-safe base64-encoded Fernet key. When provided, the data subset is decrypted for a report generation. **Important**: The same key used during a training must be used during a report generation to successfully decrypt the data.\n",
    "\n",
    "\n",
    "*Note:* For full documentation, metadata file format, and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "356f83d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:18:24.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/tmp_store/housing/merged_infer_housing.csv' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/tmp_store/housing/infer_message.success' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.291\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_check_existence_of_destination\u001b[0m:\u001b[36m172\u001b[0m - \u001b[33m\u001b[1mAs the destination path wasn't specified for the table - 'housing', the synthetic data will be stored at the default path - './model_artifacts/tmp_store/housing/merged_infer_housing.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_collect_errors\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mThe validation of the metadata has been passed successfully\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.292\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcheck_mlflow_server\u001b[0m:\u001b[36m32\u001b[0m - \u001b[33m\u001b[1mMLFlow server URL not provided\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.292\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcreate_tracker\u001b[0m:\u001b[36m69\u001b[0m - \u001b[33m\u001b[1mMLFlow server is either unreachable or not set up, therefore the tracking will not be performed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.infer\u001b[0m:\u001b[36mlaunch_infer\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mThe inference process will be executed according to the information mentioned in 'infer_settings' in the metadata file. If appropriate information is absent from the metadata file, then the values of parameters sent through CLI will be used. Otherwise, the values of parameters will be defaulted.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m520\u001b[0m - \u001b[1mInfer process of the table - 'housing' has started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/157 [..............................] - ETA: 21s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:18:24.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36mload_state\u001b[0m:\u001b[36m554\u001b[0m - \u001b[1mLoaded VAE state from model_artifacts/resources/housing/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mTotal of 20 batch(es)\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 1 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:24.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4564.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:25.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:25.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 2 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:25.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:25.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4705.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:25.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:25.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 3 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:25.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:25.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4631.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:26.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:26.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 4 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:26.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:26.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4833.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:26.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:26.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 5 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:26.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:26.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4955.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:27.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:27.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 6 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:27.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:27.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4673.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:27.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:27.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 7 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:27.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:27.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 5041.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:28.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:28.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 8 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:28.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:28.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4792.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:28.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:28.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 9 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:28.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:28.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4343.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:29.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:29.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 10 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:29.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:29.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 5061.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:29.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:29.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 11 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:29.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:29.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4957.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:29.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:29.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 12 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:29.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:29.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4731.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:30.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:30.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 13 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:30.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:30.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4973.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:30.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:30.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 14 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:30.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:30.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4665.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:31.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:31.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 15 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:31.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:31.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4906.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:31.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:31.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 16 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:31.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:31.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4971.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:32.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:32.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 17 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:32.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:32.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 5031.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:32.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:32.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 18 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:32.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:32.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4805.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:33.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:33.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 19 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:33.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:33.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4961.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:18:33.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:33.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 20 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:33.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:33.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4457.71it/s]\n",
      "\u001b[32m2026-01-05 14:18:34.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:34.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mSynthesis of the table - 'housing' was completed. Synthetic data saved in 'model_artifacts/tmp_store/housing/merged_infer_housing.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:34.489\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36mgenerate_report\u001b[0m:\u001b[36m241\u001b[0m - \u001b[33m\u001b[1mThe report(s) generation might be time-consuming\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:34.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:18:35.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.8454\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 45/45 [00:19<00:00,  2.28it/s]\n",
      "\u001b[32m2026-01-05 14:19:00.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0.1536\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:01.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.0024\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:01.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 9/9 [00:01<00:00,  7.11it/s]\n",
      "\u001b[32m2026-01-05 14:19:03.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1498\u001b[0m - \u001b[1mThe ratio of synthetic multiclass accuracy to original is 0.5266. The model considers the 'ocean_proximity' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:03.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'households' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:03.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:03.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing' has been generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The example of inference for the single table\n",
    "\n",
    "launcher_for_single_table_with_source.infer(\n",
    "    size=100000,\n",
    "    run_parallel=False,\n",
    "    batch_size=5000,\n",
    "    random_seed=42,\n",
    "    reports=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "249db062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'housing': {'path_to_input_data': 'model_artifacts/tmp_store/housing/input_data_housing.pkl',\n",
       "  'path_to_generated_data': 'model_artifacts/tmp_store/housing/merged_infer_housing.csv',\n",
       "  'generated_reports': {'accuracy_report': 'model_artifacts/tmp_store/housing/reports/accuracy-report-2026_01_05_14_19_03_500677.html'}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launcher_for_single_table_with_source.execution_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d31902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:19:26.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/tmp_store/housing/merged_infer_housing.csv' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/tmp_store/housing/infer_message.success' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.393\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_check_existence_of_destination\u001b[0m:\u001b[36m172\u001b[0m - \u001b[33m\u001b[1mAs the destination path wasn't specified for the table - 'housing', the synthetic data will be stored at the default path - './model_artifacts/tmp_store/housing/merged_infer_housing.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_collect_errors\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mThe validation of the metadata has been passed successfully\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.394\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcheck_mlflow_server\u001b[0m:\u001b[36m32\u001b[0m - \u001b[33m\u001b[1mMLFlow server URL not provided\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.394\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcreate_tracker\u001b[0m:\u001b[36m69\u001b[0m - \u001b[33m\u001b[1mMLFlow server is either unreachable or not set up, therefore the tracking will not be performed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.infer\u001b[0m:\u001b[36mlaunch_infer\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mThe inference process will be executed according to the information mentioned in 'infer_settings' in the metadata file. If appropriate information is absent from the metadata file, then the values of parameters sent through CLI will be used. Otherwise, the values of parameters will be defaulted.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m520\u001b[0m - \u001b[1mInfer process of the table - 'housing' has started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/157 [..............................] - ETA: 21s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:19:26.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36mload_state\u001b[0m:\u001b[36m554\u001b[0m - \u001b[1mLoaded VAE state from model_artifacts/resources/housing/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mTotal of 20 batch(es)\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 1 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:26.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 3877.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:27.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:27.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 2 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:27.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:27.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4068.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:27.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:27.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 3 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:27.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:27.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4310.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:28.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:28.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 4 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:28.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:28.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4269.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:28.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:28.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 5 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:28.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:28.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4563.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:29.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:29.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 6 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:29.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:29.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 3945.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:29.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:29.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 7 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:29.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:29.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4635.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:30.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:30.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 8 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:30.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:30.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4520.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:30.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:30.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 9 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:30.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:30.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4325.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:31.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:31.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 10 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:31.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:31.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4972.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:31.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:31.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 11 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:31.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:31.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 3612.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:32.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:32.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 12 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:32.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:32.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4518.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:32.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:32.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 13 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:32.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:32.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4858.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83/157 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:32.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:32.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 14 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:32.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:32.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4772.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:33.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:33.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 15 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:33.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:33.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4664.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:33.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:33.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 16 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:33.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:33.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 5006.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:34.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:34.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 17 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:34.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:34.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4956.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:34.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:34.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 18 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:34.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:34.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4446.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:35.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:35.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 19 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:35.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:35.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4261.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:19:35.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:35.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing'. Generating the batch 20 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:35.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:35.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4578.48it/s]\n",
      "\u001b[32m2026-01-05 14:19:36.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:36.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mSynthesis of the table - 'housing' was completed. Synthetic data saved in 'model_artifacts/tmp_store/housing/merged_infer_housing.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:36.514\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36mgenerate_report\u001b[0m:\u001b[36m241\u001b[0m - \u001b[33m\u001b[1mThe report(s) generation might be time-consuming\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:36.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:19:37.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.8454\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 45/45 [00:19<00:00,  2.28it/s]\n",
      "\u001b[32m2026-01-05 14:20:02.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0.1536\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:02.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.0024\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:02.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s]\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 9/9 [00:01<00:00,  7.01it/s]\n",
      "\u001b[32m2026-01-05 14:20:04.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1498\u001b[0m - \u001b[1mThe ratio of synthetic multiclass accuracy to original is 0.5266. The model considers the 'ocean_proximity' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:04.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'households' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:04.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:04.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing' has been generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The example of inference for the single table\n",
    "\n",
    "launcher_for_single_table_with_loader.infer(\n",
    "    size=100000,\n",
    "    run_parallel=False,\n",
    "    batch_size=5000,\n",
    "    random_seed=42,\n",
    "    reports=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8abd86f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'housing': {'path_to_input_data': 'model_artifacts/tmp_store/housing/input_data_housing.pkl',\n",
       "  'path_to_generated_data': 'model_artifacts/tmp_store/housing/merged_infer_housing.csv',\n",
       "  'generated_reports': {'accuracy_report': 'model_artifacts/tmp_store/housing/reports/accuracy-report-2026_01_05_14_20_04_759854.html'}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launcher_for_single_table_with_loader.execution_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31cfc222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:20:17.683\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.validation_schema.validation_schema\u001b[0m:\u001b[36mvalidate_schema\u001b[0m:\u001b[36m348\u001b[0m - \u001b[34m\u001b[1mThe schema of the metadata is valid\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/tmp_store/housing-properties/merged_infer_housing-properties.csv' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/tmp_store/housing-properties/infer_message.success' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/tmp_store/housing-conditions/merged_infer_housing-conditions.csv' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_remove_existed_artifact\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe artifacts located in the path - 'model_artifacts/tmp_store/housing-conditions/infer_message.success' was removed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.684\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_check_existence_of_destination\u001b[0m:\u001b[36m172\u001b[0m - \u001b[33m\u001b[1mAs the destination path wasn't specified for the table - 'housing_properties', the synthetic data will be stored at the default path - './model_artifacts/tmp_store/housing-properties/merged_infer_housing-properties.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.684\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_check_existence_of_destination\u001b[0m:\u001b[36m172\u001b[0m - \u001b[33m\u001b[1mAs the destination path wasn't specified for the table - 'housing_conditions', the synthetic data will be stored at the default path - './model_artifacts/tmp_store/housing-conditions/merged_infer_housing-conditions.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_collect_errors\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mThe validation of the metadata has been passed successfully\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.685\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcheck_mlflow_server\u001b[0m:\u001b[36m32\u001b[0m - \u001b[33m\u001b[1mMLFlow server URL not provided\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.685\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcreate_tracker\u001b[0m:\u001b[36m69\u001b[0m - \u001b[33m\u001b[1mMLFlow server is either unreachable or not set up, therefore the tracking will not be performed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.infer\u001b[0m:\u001b[36mlaunch_infer\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mThe inference process will be executed according to the information mentioned in 'infer_settings' in the metadata file. If appropriate information is absent from the metadata file, then the values of parameters sent through CLI will be used. Otherwise, the values of parameters will be defaulted.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:17.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m520\u001b[0m - \u001b[1mInfer process of the table - 'housing_properties' has started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:20:18.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36mload_state\u001b[0m:\u001b[36m554\u001b[0m - \u001b[1mLoaded VAE state from model_artifacts/resources/housing-properties/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.043\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m490\u001b[0m - \u001b[34m\u001b[1mInfer model with parameters: size=90, run_parallel=False, batch_size=90, random_seed=10, reports - 'accuracy'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mTotal of 1 batch(es)\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_properties'. Generating the batch 1 of 1\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_properties' started.\u001b[0m\n",
      "Generation of the data...: 100%|██████████| 7/7 [00:00<00:00, 10089.39it/s]\n",
      "\u001b[32m2026-01-05 14:20:18.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mSynthesis of the table - 'housing_properties' was completed. Synthetic data saved in 'model_artifacts/tmp_store/housing-properties/merged_infer_housing-properties.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m520\u001b[0m - \u001b[1mInfer process of the table - 'housing_conditions' has started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:20:18.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36mload_state\u001b[0m:\u001b[36m554\u001b[0m - \u001b[1mLoaded VAE state from model_artifacts/resources/housing-conditions/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.419\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m490\u001b[0m - \u001b[34m\u001b[1mInfer model with parameters: size=90, run_parallel=False, batch_size=90, random_seed=10, reports - 'accuracy'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mTotal of 1 batch(es)\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_conditions'. Generating the batch 1 of 1\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_conditions' started.\u001b[0m\n",
      "Generation of the data...: 100%|██████████| 3/3 [00:00<00:00, 5238.51it/s]\n",
      "\u001b[32m2026-01-05 14:20:18.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mgenerate_keys\u001b[0m:\u001b[36m428\u001b[0m - \u001b[1mThe 'households' assigned as a foreign_key feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mSynthesis of the table - 'housing_conditions' was completed. Synthetic data saved in 'model_artifacts/tmp_store/housing-conditions/merged_infer_housing-conditions.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.539\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36mgenerate_report\u001b[0m:\u001b[36m241\u001b[0m - \u001b[33m\u001b[1mThe report(s) generation might be time-consuming\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing_conditions' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:18.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.8853\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n",
      "\u001b[32m2026-01-05 14:20:22.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:22.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.1833\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:22.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "\u001b[32m2026-01-05 14:20:22.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36m__model_process\u001b[0m:\u001b[36m1583\u001b[0m - \u001b[1mThe best score for all possible multiclass classification models for the original data is 0.0611, which is below 0.6. The utility metric is unreliable\u001b[0m\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 2/2 [00:00<00:00,  6.83it/s]\n",
      "\u001b[32m2026-01-05 14:20:23.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1498\u001b[0m - \u001b[1mThe ratio of synthetic multiclass accuracy to original is 4.5455. The model considers the 'housing_median_age' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:23.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'total_rooms' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:23.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:23.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing_conditions' has been generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:23.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing_properties' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:23.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.7942\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s]\n",
      "\u001b[32m2026-01-05 14:20:30.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:30.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.35\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:30.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s]\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 5/5 [00:00<00:00,  7.11it/s]\n",
      "\u001b[32m2026-01-05 14:20:31.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1498\u001b[0m - \u001b[1mThe ratio of synthetic multiclass accuracy to original is 0.7296. The model considers the 'ocean_proximity' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:31.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'longitude' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:31.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:20:31.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing_properties' has been generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The example of inference of multiple tables with relationships\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.infer(log_level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd28f7",
   "metadata": {},
   "source": [
    "The *'execution_artifacts'* attribute of the **Syngen** class provides information about the generated artifacts during the inference process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c474b6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'housing_conditions': {'generated_reports': {'accuracy_report': 'model_artifacts/tmp_store/housing-conditions/reports/accuracy-report-2026_01_05_14_20_23_407937.html'},\n",
      "                        'path_to_generated_data': 'model_artifacts/tmp_store/housing-conditions/merged_infer_housing-conditions.csv',\n",
      "                        'path_to_input_data': 'model_artifacts/tmp_store/housing-conditions/input_data_housing-conditions.pkl'},\n",
      " 'housing_properties': {'generated_reports': {'accuracy_report': 'model_artifacts/tmp_store/housing-properties/reports/accuracy-report-2026_01_05_14_20_31_359266.html'},\n",
      "                        'path_to_generated_data': 'model_artifacts/tmp_store/housing-properties/merged_infer_housing-properties.csv',\n",
      "                        'path_to_input_data': 'model_artifacts/tmp_store/housing-properties/input_data_housing-properties.pkl'}}\n"
     ]
    }
   ],
   "source": [
    "pprint(launcher_for_multiple_tables.execution_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a6385",
   "metadata": {},
   "source": [
    "# Data security: Using Fernet Key for encryption\n",
    "\n",
    "In the current implementation, a sample of the original data is stored on a disk during a training process. To ensure data security and protect sensitive information, you can use a **Fernet key** to encrypt this data.\n",
    "\n",
    "## What is a Fernet Key?\n",
    "\n",
    "A Fernet key is a 44-character URL-safe base64-encoded string used for symmetric encryption. When provided, the data subset is encrypted on a disk (stored in the `.dat` format instead of unencrypted `.pkl` format).\n",
    "\n",
    "## How to Generate a Fernet Key\n",
    "\n",
    "You can generate a Fernet key using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1cee26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Fernet key\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "fernet_key = Fernet.generate_key().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd259dc",
   "metadata": {},
   "source": [
    "## Setting the Fernet Key as an environment variable\n",
    "\n",
    "After generating the key, you need to store it as an environment variable. This can be done in your terminal or programmatically in Python.\n",
    "\n",
    "### Option 1: Set in Terminal (Linux/macOS)\n",
    "\n",
    "```bash\n",
    "export MY_FERNET_KEY='your_generated_fernet_key_here'\n",
    "```\n",
    "\n",
    "### Option 2: Set in Terminal (Windows)\n",
    "\n",
    "```cmd\n",
    "set MY_FERNET_KEY=your_generated_fernet_key_here\n",
    "```\n",
    "\n",
    "### Option 3: Set programmatically in Python\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ['MY_FERNET_KEY'] = 'your_generated_fernet_key_here'\n",
    "```\n",
    "\n",
    "## Using the Fernet Key in a training\n",
    "\n",
    "When training with encryption, pass the name of the environment variable (not the Fernet key itself) to the `fernet_key` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3ece919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:24:10.226\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_launch_validation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mEncryption and decryption are enabled for the table 'housing_encrypted' as a Fernet key is provided\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_collect_errors\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mThe validation of the metadata has been passed successfully\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.228\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcheck_mlflow_server\u001b[0m:\u001b[36m32\u001b[0m - \u001b[33m\u001b[1mMLFlow server URL not provided\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.228\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcreate_tracker\u001b[0m:\u001b[36m69\u001b[0m - \u001b[33m\u001b[1mMLFlow server is either unreachable or not set up, therefore the tracking will not be performed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.train\u001b[0m:\u001b[36mlaunch_train\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mThe training process will be executed according to the information mentioned in 'train_settings' in the metadata file. If appropriate information is absent from the metadata file, then the values of parameters sent through CLI will be used. Otherwise, the values of parameters will be defaulted.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.processors.processors\u001b[0m:\u001b[36m_preprocess_data\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mThe subset of rows was set to 1000\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_train_table\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mTraining process of the table - 'housing_encrypted' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mStart VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_pk_key\u001b[0m:\u001b[36m210\u001b[0m - \u001b[1mNo primary key was set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_uq_keys\u001b[0m:\u001b[36m267\u001b[0m - \u001b[1mNo unique keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m__set_fk_keys\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mNo foreign keys were set.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'longitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'latitude' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'housing_median_age' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_rooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_preprocess_nan_cols\u001b[0m:\u001b[36m1206\u001b[0m - \u001b[1mColumn 'total_bedrooms' contains 11 (1.1%) empty values out of 1000. Filling them with mean.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'total_bedrooms' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mColumn 'total_bedrooms_null' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'population' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'households' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_float_feature\u001b[0m:\u001b[36m1368\u001b[0m - \u001b[1mColumn 'median_income' assigned as float based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_int_feature\u001b[0m:\u001b[36m1376\u001b[0m - \u001b[1mColumn 'median_house_value' assigned as int based feature\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:10.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.dataset\u001b[0m:\u001b[36m_assign_categ_feature\u001b[0m:\u001b[36m1392\u001b[0m - \u001b[1mColumn 'ocean_proximity' assigned as categorical based feature.\u001b[0m\n",
      "31it [00:03,  8.19it/s]\n",
      "\u001b[32m2026-01-05 14:24:14.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 0, total loss: 2.7609105110168457, time: 3.8273 sec\u001b[0m\n",
      "31it [00:03,  9.85it/s]\n",
      "\u001b[32m2026-01-05 14:24:17.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 1, total loss: 2.3663723468780518, time: 3.1799 sec\u001b[0m\n",
      "31it [00:03,  9.78it/s]\n",
      "\u001b[32m2026-01-05 14:24:21.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 2, total loss: 2.1577329635620117, time: 3.1997 sec\u001b[0m\n",
      "31it [00:03,  9.84it/s]\n",
      "\u001b[32m2026-01-05 14:24:24.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 3, total loss: 1.9387649297714233, time: 3.1821 sec\u001b[0m\n",
      "31it [00:03,  9.75it/s]\n",
      "\u001b[32m2026-01-05 14:24:27.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_train\u001b[0m:\u001b[36m410\u001b[0m - \u001b[1mepoch: 4, total loss: 1.859651803970337, time: 3.2129 sec\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:27.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFit sampler\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:27.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1mStart encoding\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 846us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:24:27.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m187\u001b[0m - \u001b[1mCreating BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:27.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mFitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:29.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.models.model\u001b[0m:\u001b[36mfit_sampler\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished fitting BayesianGaussianMixture\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:29.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36msave_state\u001b[0m:\u001b[36m545\u001b[0m - \u001b[1mSaved VAE state in model_artifacts/resources/housing-encrypted/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:29.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36m__fit_model\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mFinished VAE training\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:29.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mNo columns to train kde over found\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:29.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mTraining of the table - 'housing_encrypted' was completed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:24:29.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.data_loaders.data_loaders\u001b[0m:\u001b[36msave_data\u001b[0m:\u001b[36m681\u001b[0m - \u001b[1mData is successfully encrypted and saved to 'model_artifacts/tmp_store/housing-encrypted/input_data_housing-encrypted.dat'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# The example: the training with the Fernet key encryption\n",
    "\n",
    "import os\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "# Step 1: Set the Fernet key as an environment variable\n",
    "os.environ[\"MY_FERNET_KEY\"] = fernet_key  # Using the key generated above\n",
    "\n",
    "# Step 2: Train with encryption enabled\n",
    "\n",
    "launcher_for_encrypted_data = Syngen(\n",
    "    source=\"../examples/example-data/housing.csv\", \n",
    "    table_name=\"housing_encrypted\"\n",
    ")\n",
    "\n",
    "launcher_for_encrypted_data.train(\n",
    "    epochs=5,\n",
    "    row_limit=1000, \n",
    "    batch_size=32, \n",
    "    fernet_key=\"MY_FERNET_KEY\"  # Pass the environment variable name, not the key itself\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "063fe961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'housing_encrypted': {'losses_path': 'model_artifacts/system_store/losses/losses-housing-encrypted-2026-01-05-14-24-10-306201.csv',\n",
       "  'path_to_input_data': 'model_artifacts/tmp_store/housing-encrypted/input_data_housing-encrypted.dat',\n",
       "  'generated_reports': {}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launcher_for_encrypted_data.execution_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed5c1b",
   "metadata": {},
   "source": [
    "## Using the Fernet Key in an inference\n",
    "\n",
    "**Important**: When generating synthetic data during an inference process, you must use the **same Fernet key** that was used during a training process. This allows the system to decrypt the stored data subset for a report generation.\n",
    "\n",
    "If the Fernet key is not provided or doesn't match the Fernet key used in the training process, the inference process will fail when trying to access the encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d3788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:27:11.949\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_launch_validation\u001b[0m:\u001b[36m394\u001b[0m - \u001b[33m\u001b[1mEncryption and decryption are enabled for the table 'housing_encrypted' as a Fernet key is provided\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:11.951\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_check_existence_of_destination\u001b[0m:\u001b[36m172\u001b[0m - \u001b[33m\u001b[1mAs the destination path wasn't specified for the table - 'housing_encrypted', the synthetic data will be stored at the default path - './model_artifacts/tmp_store/housing-encrypted/merged_infer_housing-encrypted.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:11.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.data_loaders.data_loaders\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m706\u001b[0m - \u001b[1mData stored at the path - 'model_artifacts/tmp_store/housing-encrypted/input_data_housing-encrypted.dat' has been successfully decrypted and loaded.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:11.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.config.validation\u001b[0m:\u001b[36m_collect_errors\u001b[0m:\u001b[36m435\u001b[0m - \u001b[1mThe validation of the metadata has been passed successfully\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:11.953\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcheck_mlflow_server\u001b[0m:\u001b[36m32\u001b[0m - \u001b[33m\u001b[1mMLFlow server URL not provided\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:11.953\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.mlflow_tracker.mlflow_tracker\u001b[0m:\u001b[36mcreate_tracker\u001b[0m:\u001b[36m69\u001b[0m - \u001b[33m\u001b[1mMLFlow server is either unreachable or not set up, therefore the tracking will not be performed\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:11.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.infer\u001b[0m:\u001b[36mlaunch_infer\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mThe inference process will be executed according to the information mentioned in 'infer_settings' in the metadata file. If appropriate information is absent from the metadata file, then the values of parameters sent through CLI will be used. Otherwise, the values of parameters will be defaulted.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:11.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.worker.worker\u001b[0m:\u001b[36m_infer_table\u001b[0m:\u001b[36m520\u001b[0m - \u001b[1mInfer process of the table - 'housing_encrypted' has started\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/157 [..............................] - ETA: 21s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:27:12.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36mload_state\u001b[0m:\u001b[36m554\u001b[0m - \u001b[1mLoaded VAE state from model_artifacts/resources/housing-encrypted/vae/checkpoints\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:12.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mTotal of 20 batch(es)\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:12.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 1 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:12.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:12.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 3821.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:13.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:13.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 2 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:13.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:13.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 3885.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:13.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:13.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 3 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:13.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:13.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 3915.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:13.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:13.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 4 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:13.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:13.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4446.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:14.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:14.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 5 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:14.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:14.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4130.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:14.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:14.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 6 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:14.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:14.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4569.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:15.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:15.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 7 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:15.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:15.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4100.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:15.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:15.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 8 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:15.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:15.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4194.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:16.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:16.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 9 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:16.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:16.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4546.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:16.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:16.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 10 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:16.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:16.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4531.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:17.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:17.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 11 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:17.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:17.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4988.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:17.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:17.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 12 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:17.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:17.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4790.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:18.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:18.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 13 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:18.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:18.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 5115.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/157 [=================>............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:18.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:18.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 14 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:18.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:18.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4974.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 91/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:18.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:18.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 15 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:18.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:18.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 5049.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:19.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:19.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 16 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:19.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:19.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 5029.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:19.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:19.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 17 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:19.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:19.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 5164.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/157 [================>.............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:20.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:20.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 18 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:20.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:20.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4982.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:20.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:20.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 19 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:20.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:20.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 5063.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/157 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2026-01-05 14:27:21.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:21.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mhandle\u001b[0m:\u001b[36m503\u001b[0m - \u001b[1mData synthesis for the table - 'housing_encrypted'. Generating the batch 20 of 20\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:21.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mStart data synthesis\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:21.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.handlers.handlers\u001b[0m:\u001b[36mrun_separate\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mVAE generation for 'housing_encrypted' started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation of the data...: 100%|██████████| 11/11 [00:00<00:00, 4893.13it/s]\n",
      "\u001b[32m2026-01-05 14:27:21.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.vae.wrappers.wrappers\u001b[0m:\u001b[36m_restore_nan_values\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mColumn 'total_bedrooms' has 0 (0.0%) empty values generated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:22.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.strategies.strategies\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m236\u001b[0m - \u001b[1mSynthesis of the table - 'housing_encrypted' was completed. Synthetic data saved in 'model_artifacts/tmp_store/housing-encrypted/merged_infer_housing-encrypted.csv'\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:22.104\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36mgenerate_report\u001b[0m:\u001b[36m241\u001b[0m - \u001b[33m\u001b[1mThe report(s) generation might be time-consuming\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:22.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing_encrypted' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:22.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.data_loaders.data_loaders\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m706\u001b[0m - \u001b[1mData stored at the path - 'model_artifacts/tmp_store/housing-encrypted/input_data_housing-encrypted.dat' has been successfully decrypted and loaded.\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:23.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.7722\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 45/45 [00:20<00:00,  2.22it/s]\n",
      "\u001b[32m2026-01-05 14:27:47.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0.6237\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:48.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.0023\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:48.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[32m2026-01-05 14:27:48.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36m_valid_target\u001b[0m:\u001b[36m1683\u001b[0m - \u001b[1mColumn 'ocean_proximity' has a class with less than 2 samples. It will not be used as target column in utility metric calculation for multiclass classification.\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00, 320.30it/s]\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 9/9 [00:01<00:00,  7.05it/s]\n",
      "\u001b[32m2026-01-05 14:27:50.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'households' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:50.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:27:50.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing_encrypted' has been generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Example: Inference with Fernet key decryption\n",
    "# The environment variable 'MY_FERNET_KEY' is already set from the training step\n",
    "\n",
    "# Inference with the same Fernet key\n",
    "launcher_for_encrypted_data.infer(\n",
    "    size=100000,\n",
    "    batch_size=5000, \n",
    "    random_seed=42,\n",
    "    reports=\"all\",\n",
    "    fernet_key=\"MY_FERNET_KEY\"  # Must use the same key as in a training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "185937e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'housing_encrypted': {'path_to_input_data': 'model_artifacts/tmp_store/housing-encrypted/input_data_housing-encrypted.dat',\n",
       "  'path_to_generated_data': 'model_artifacts/tmp_store/housing-encrypted/merged_infer_housing-encrypted.csv',\n",
       "  'generated_reports': {'accuracy_report': 'model_artifacts/tmp_store/housing-encrypted/reports/accuracy-report-2026_01_05_14_27_50_276239.html'}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launcher_for_encrypted_data.execution_artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3232e8",
   "metadata": {},
   "source": [
    "## Using the Fernet Key with the metadata file\n",
    "\n",
    "You can also specify the Fernet key in the metadata file for both training and inference:\n",
    "\n",
    "```yaml\n",
    "global:\n",
    "  encryption:\n",
    "    fernet_key: MY_FERNET_KEY  # Name of the environment variable\n",
    "\n",
    "TABLE_NAME:\n",
    "  train_settings:\n",
    "    source: \"./data/table.csv\"\n",
    "  \n",
    "  infer_settings:\n",
    "    size: 100\n",
    "  \n",
    "  # You can also specify per-table encryption\n",
    "  encryption:\n",
    "    fernet_key: MY_FERNET_KEY\n",
    "```\n",
    "\n",
    "Then use it in your code:\n",
    "\n",
    "```python\n",
    "# Training with the metadata file and the Fernet key\n",
    "Syngen(metadata_path=\"path/to/metadata.yaml\").train()\n",
    "\n",
    "# Inference with the metadata file and the Fernet key\n",
    "Syngen(metadata_path=\"path/to/metadata.yaml\").infer()\n",
    "```\n",
    "\n",
    "## Important security notes\n",
    "\n",
    "⚠️ **Critical security considerations:**\n",
    "\n",
    "1. **Store the key securely**: Never hardcode the Fernet key directly in your code or commit it to version control systems.\n",
    "2. **Key recovery is impossible**: If you lose the Fernet key, encrypted data cannot be recovered\n",
    "3. **Same key required**: Always use the same Fernet key for a training, an inference and a report generation\n",
    "4. **Environment variable**: Use an environment variable to store the Fernet key securely\n",
    "5. **Key length**: The Fernet key must be exactly 44 characters (URL-safe base64-encoded)\n",
    "6. **Production environments**: In production, use secure secret management services (AWS Secrets Manager, Azure Key Vault, HashiCorp Vault, etc.)\n",
    "\n",
    "## What happens without a Fernet key?\n",
    "\n",
    "If you don't provide a `fernet_key` parameter:\n",
    "- Data subset is stored **unencrypted** in the `.pkl` format\n",
    "- No decryption is needed during the inference or the report generation\n",
    "- Suitable for non-sensitive data or development environments\n",
    "\n",
    "With a `fernet_key`:\n",
    "- Data subset is stored **encrypted** in the `.dat` format\n",
    "- Decryption is required during the inference or the report generation using the same Fernet key\n",
    "- Recommended for sensitive or production data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e90b1a",
   "metadata": {},
   "source": [
    "# Generate quality reports separately\n",
    "\n",
    "Sometimes you may want to generate quality reports separately after training or/and inference has already been completed to evaluate the quality of the input data or the generated data. The SDK provides the `Syngen().generate_quality_reports(...)` method that allows you to generate quality reports for a table using existing artifacts without re-running the training or/and inference processes.\n",
    "\n",
    "This method is useful when:\n",
    "- You completed training/inference without quality reports (with `reports=\"none\"`)\n",
    "- You want to generate additional report types later\n",
    "- You want to separate the computation-intensive training/inference from report generation\n",
    "\n",
    "\n",
    "```python\n",
    "generate_quality_reports(\n",
    "    self,\n",
    "    table_name: str,                        # required: the name of the table to generate quality reports for\n",
    "    reports: Union[str, Tuple[str], List[str]], # required: report types to generate\n",
    "    fernet_key: Optional[str] = None        # optional: a Fernet key for decrypting encrypted data\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters description:\n",
    "\n",
    "- **`table_name`** *(str, required)*: The name of the table to generate reports for.\n",
    "\n",
    "- **`reports`** *(Union[str, Tuple[str], List[str]], required)*: Controls which quality reports to generate. Accepts single string or list of strings:\n",
    "  - `\"accuracy\"` - generates an accuracy report comparing original and synthetic data\n",
    "  - `\"metrics_only\"` - outputs metrics information to stdout without generating an accuracy report\n",
    "  - `\"sample\"` - generates a sample report showing distribution comparisons between original data and the data subset used for a training process\n",
    "  - `\"all\"` - generates all available reports (*\"accuracy\"* and *\"sample\"*)\n",
    "  \n",
    "  List example: `[\"accuracy\", \"sample\"]` to generate multiple report types.\n",
    "\n",
    "  *Note*: Report generation may require significant time for large tables (>10,000 rows)\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: The name of the environment variable containing the Fernet key used to decrypt the original data subset. **Important**: Must be the same key used during training if the data was encrypted.\n",
    "\n",
    "### Required artifacts\n",
    "\n",
    "To generate quality reports, the following artifacts must exist:\n",
    "\n",
    "**For accuracy reports (`\"accuracy\"` or `\"metrics_only\"`):**\n",
    "- Training must be completed successfully\n",
    "- Inference must be completed successfully\n",
    "\n",
    "**For a `\"sample\"` report:**\n",
    "- Training must be completed successfully\n",
    "\n",
    "### Key notes:\n",
    "\n",
    "- The method uses existing artifacts and does not re-run a training or an inference process\n",
    "- All required artifacts must be present in the `model_artifacts` directory\n",
    "- The `table_name` must match exactly the name of the `table_name` that was used in a training/inference process\n",
    "- If data was encrypted during a training, the same `fernet_key` must be provided\n",
    "\n",
    "*Note:* For full documentation and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59f71f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 14:39:44.321\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36mgenerate_report\u001b[0m:\u001b[36m241\u001b[0m - \u001b[33m\u001b[1mThe report(s) generation might be time-consuming\u001b[0m\n",
      "\u001b[32m2026-01-05 14:39:44.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe calculation of accuracy metrics for the table - 'housing_conditions' has started\u001b[0m\n",
      "\u001b[32m2026-01-05 14:39:44.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mMedian accuracy is 0.8853\u001b[0m\n",
      "Generating bivariate distributions...: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "\u001b[32m2026-01-05 14:39:47.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1mMedian of differences of correlations is 0\u001b[0m\n",
      "\u001b[32m2026-01-05 14:39:47.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.accuracy_test.accuracy_test\u001b[0m:\u001b[36m_fetch_metrics\u001b[0m:\u001b[36m229\u001b[0m - \u001b[1mMean clusters homogeneity is 0.1833\u001b[0m\n",
      "\u001b[32m2026-01-05 14:39:47.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCalculating utility metric\u001b[0m\n",
      "Calculating utility metric for multiclass classification: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
      "\u001b[32m2026-01-05 14:39:48.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36m__model_process\u001b[0m:\u001b[36m1583\u001b[0m - \u001b[1mThe best score for all possible multiclass classification models for the original data is 0.0611, which is below 0.6. The utility metric is unreliable\u001b[0m\n",
      "Calculating utility metric for binary classification: 0it [00:00, ?it/s]\n",
      "Calculating utility metric for regression: 100%|██████████| 2/2 [00:00<00:00,  7.32it/s]\n",
      "\u001b[32m2026-01-05 14:39:48.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1498\u001b[0m - \u001b[1mThe ratio of synthetic multiclass accuracy to original is 4.5455. The model considers the 'housing_median_age' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:39:48.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1508\u001b[0m - \u001b[1mThe ratio of synthetic regression accuracy to original is 0.0. The model considers the 'total_rooms' column as a target and other columns as predictors\u001b[0m\n",
      "\u001b[32m2026-01-05 14:39:48.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.metrics.metrics_classes.metrics\u001b[0m:\u001b[36mcalculate_all\u001b[0m:\u001b[36m1514\u001b[0m - \u001b[1mUtility metric is calculated\u001b[0m\n",
      "\u001b[32m2026-01-05 14:39:48.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msyngen.ml.reporters.reporters\u001b[0m:\u001b[36m_log_and_update_progress\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mThe accuracy report of the table - 'housing_conditions' has been generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Generate an accuracy report after a training and inference process completed without a generation of quality reports.\n",
    "# Assume a training and inference process were already completed with reports=\"none\".\n",
    "# Now generate an accuracy report separately.\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_conditions\",\n",
    "    reports=\"accuracy\",\n",
    "    log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e90dbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'housing_conditions': {'generated_reports': {'accuracy_report': 'model_artifacts/tmp_store/housing-conditions/reports/accuracy-report-2026_01_05_14_39_48_565198.html'}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launcher_for_multiple_tables.execution_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9e5879a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrainConfig' object has no attribute 'loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example 2: Generate a sample report after training completed\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Generate a sample report to compare original data with its subset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mlauncher_for_multiple_tables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_quality_reports\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhousing_properties\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreports\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msample\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/sdk.py:516\u001b[39m, in \u001b[36mSyngen.generate_quality_reports\u001b[39m\u001b[34m(self, table_name, reports, log_level, fernet_key)\u001b[39m\n\u001b[32m    505\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_artifacts(\n\u001b[32m    506\u001b[39m         table_name=table_name,\n\u001b[32m    507\u001b[39m         completed_processes={\n\u001b[32m   (...)\u001b[39m\u001b[32m    512\u001b[39m         }\n\u001b[32m    513\u001b[39m     )\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m reports:\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_register_reporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfernet_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reports:\n\u001b[32m    519\u001b[39m     Report().generate_report()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/sdk.py:467\u001b[39m, in \u001b[36mSyngen._register_reporter\u001b[39m\u001b[34m(self, table_name, report, fernet_key)\u001b[39m\n\u001b[32m    465\u001b[39m     Report().register_reporter(table=table_name, reporter=accuracy_reporter)\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m report == \u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     sample_reporter = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_sample_reporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfernet_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m     Report().register_reporter(table=table_name, reporter=sample_reporter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pycharm/syngen/venv311local/lib/python3.11/site-packages/syngen/sdk.py:438\u001b[39m, in \u001b[36mSyngen.__get_sample_reporter\u001b[39m\u001b[34m(self, table_name, fernet_key)\u001b[39m\n\u001b[32m    431\u001b[39m train_config = \u001b[38;5;28mself\u001b[39m._get_config(table_name, type_of_process=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    432\u001b[39m train_config.metadata[table_name][\u001b[33m\"\u001b[39m\u001b[33mencryption\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mfernet_key\u001b[39m\u001b[33m\"\u001b[39m] = fernet_key\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m SampleAccuracyReporter(\n\u001b[32m    434\u001b[39m     table_name=table_name,\n\u001b[32m    435\u001b[39m     paths=train_config.paths,\n\u001b[32m    436\u001b[39m     config=train_config.to_dict(),\n\u001b[32m    437\u001b[39m     metadata=train_config.metadata,\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     loader=\u001b[43mtrain_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m,\n\u001b[32m    439\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'TrainConfig' object has no attribute 'loader'"
     ]
    }
   ],
   "source": [
    "# Example 2: Generate a sample report after training completed\n",
    "\n",
    "# Generate a sample report to compare original data with its subset\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_properties\",\n",
    "    reports=\"sample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Generate multiple reports at once\n",
    "\n",
    "# Generate both accuracy and sample reports\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_conditions\",\n",
    "    reports=[\"accuracy\", \"sample\"]\n",
    ")\n",
    "\n",
    "# Or use \"all\" to generate all available reports\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_conditions\",\n",
    "    reports=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b32f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Generate quality reports for encrypted data\n",
    "import os\n",
    "\n",
    "# Ensure the Fernet key environment variable is set\n",
    "# (Should be the same key used during training)\n",
    "os.environ['MY_FERNET_KEY'] = fernet_key\n",
    "\n",
    "# Generate qulaity reports with decryption\n",
    "launcher_for_encrypted_data.generate_quality_reports(\n",
    "    table_name=\"housing_encrypted\",\n",
    "    reports=\"accuracy\",\n",
    "    fernet_key=\"MY_FERNET_KEY\"  # Same key used in training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed62d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Generate the \"metrics_only\" report (without a full accuracy report)\n",
    "# Output metrics to stdout\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing\",\n",
    "    reports=\"metrics_only\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7862acd",
   "metadata": {},
   "source": [
    "# Using Custom Data Loaders\n",
    "\n",
    "The `loader_path` parameter allows you to load data from non-standard sources such as databases, APIs, cloud storage, or any custom data source. This is particularly useful when:\n",
    "- Your data is stored in a database (PostgreSQL, MySQL, MongoDB, etc.)\n",
    "- You need to fetch data from an API or web service\n",
    "- Your data is in cloud storage (AWS S3, Azure Blob, Google Cloud Storage)\n",
    "- You need to apply custom preprocessing before training/inference\n",
    "- The file format is not directly supported\n",
    "\n",
    "## Custom Loader Requirements\n",
    "\n",
    "A custom loader function must meet these requirements:\n",
    "\n",
    "1. **Accept `table_name` as the first parameter** (str): The name of the table to load\n",
    "2. **Return a pandas DataFrame**: The loaded data in DataFrame format\n",
    "\n",
    "## Function Signature\n",
    "\n",
    "```python\n",
    "def custom_loader(table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data for the specified table.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name : str\n",
    "        The name of the table to load\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The loaded data as a pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Your loading logic here\n",
    "    return dataframe\n",
    "```\n",
    "\n",
    "## Example: Basic Custom Loader\n",
    "\n",
    "The repository includes a working example in [examples/example-package/custom_loader.py](../examples/example-package/custom_loader.py):\n",
    "\n",
    "```python\n",
    "# File: examples/example-package/custom_loader.py\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_dataframe(table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a CSV file as a pandas DataFrame from the example-data directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name : str\n",
    "        The name of the table (CSV file without extension) to load\n",
    "    encoding : Optional[str], default=\"utf-8\"\n",
    "        The encoding to use when reading the CSV file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The loaded data as a pandas DataFrame\n",
    "    \"\"\"\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    path_to_example_data = current_dir / \"example-data\" / f\"{table_name}.csv\"\n",
    "    \n",
    "    if not path_to_example_data.exists():\n",
    "        raise FileNotFoundError(f\"The CSV file '{table_name}.csv' does not exist\")\n",
    "    \n",
    "    return pd.read_csv(path_to_example_data)\n",
    "```\n",
    "\n",
    "## How to Use the Custom Loader\n",
    "\n",
    "### Step 1: Ensure the loader module is importable\n",
    "\n",
    "Make sure your custom loader module is importable.\n",
    "\n",
    "### Step 2: Use the loader during the initialization of the class Syngen\n",
    "\n",
    "```python\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "launcher = Syngen(loader=get_dataframe, table_name=\"housing\")\n",
    "\n",
    "launcher.train(\n",
    "    epochs=5,\n",
    "    row_limit=1000,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "launcher.infer(\n",
    "    size=10000,\n",
    "    batch_size=5000,\n",
    "    reports=\"accuracy\"\n",
    ")\n",
    "```\n",
    "\n",
    "## Advanced Examples\n",
    "\n",
    "### Example: Database Loader\n",
    "\n",
    "```python\n",
    "# File: my_loaders/db_loader.py\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def load_from_postgres(table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Load data from PostgreSQL database.\"\"\"\n",
    "    engine = create_engine(\"TEST_CONNECTION_STRING\")\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    return pd.read_sql(query, engine)\n",
    "```\n",
    "\n",
    "Usage:\n",
    "```python\n",
    "Syngen(loader=load_from_postgres, table_name=\"test_table\")\n",
    "```\n",
    "\n",
    "### Example: API Loader\n",
    "\n",
    "```python\n",
    "# File: my_loaders/api_loader.py\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def load_from_api(table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Load data from REST API.\"\"\"\n",
    "    response = requests.get(f\"{api_url}/{table_name}\")\n",
    "    data = response.json()\n",
    "    return pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "### Example: Cloud Storage Loader\n",
    "\n",
    "```python\n",
    "# File: my_loaders/cloud_loader.py\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "def load_from_s3(table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Load data from AWS S3.\"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    obj = s3_client.get_object(Bucket=bucket_name, Key=f\"{table_name}.csv\")\n",
    "    data = obj['Body'].read().decode('utf-8')\n",
    "    return pd.read_csv(StringIO(data))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05167a9e",
   "metadata": {},
   "source": [
    "# Data loading and saving: DataIO class\n",
    "\n",
    "The SDK provides the `DataIO` class for loading and saving data in various supported formats with optional encryption and format settings. This class is useful when you need to:\n",
    "- Load and save data in different file formats (*CSV*, *Avro*, *Excel*, etc.)\n",
    "- Load and save data with specific format settings\n",
    "- Work with encrypted data files\n",
    "\n",
    "## Class initialization\n",
    "\n",
    "```python\n",
    "DataIO(\n",
    "    path: str,                          # required: a path to the data file\n",
    "    fernet_key: Optional[str] = None,   # optional: a Fernet key for encrypted data\n",
    "    **kwargs                            # optional: format settings for CSV or Excel tables, or schema for AVRO file\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters description:\n",
    "\n",
    "- **`path`** *(str, required)*: the path to the data file to load or save. Supported formats include:\n",
    "  - CSV files: `.csv`, `.psv`, `.tsv`, `.txt`\n",
    "  - Avro files: `.avro`\n",
    "  - Excel files: `.xls`, `.xlsx`\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: the name of the environment variable containing the Fernet key for encrypted data operations.\n",
    "\n",
    "- **`**kwargs`**: Optional format settings or/and a schema for reading and writing data. Available parameters depend on the file format:\n",
    "\n",
    "  **For tables in '.csv', '.psv', '.tsv', '.txt' formats:**\n",
    "  - `sep` *(str)*: Delimiter to use (e.g., `','`, `';'`, `'\\t'`)\n",
    "  - `quotechar` *(str)*: Character used to denote the start and end of a quoted item (default: `'\"'`)\n",
    "  - `quoting` *(str)*: Quoting behavior - `\"all\"`, `\"minimal\"`, `\"non-numeric\"`, `\"none\"`\n",
    "  - `escapechar` *(str)*: Character used to escape other characters\n",
    "  - `encoding` *(str)*: Encoding to use (e.g., `'utf-8'`, `'latin-1'`)\n",
    "  - `header` *(Optional[int, List[int], Literal[\"infer\"]])*: Row number(s) containing column labels and marking the start of the data\n",
    "  - `skiprows` *(Optional[int, List[int]])*: Lines to skip at the start of the file\n",
    "  - `on_bad_lines` *(Literal[\"error\", \"warn\", \"skip\"])*: Action on bad lines - `\"error\"`, `\"warn\"`, `\"skip\"`\n",
    "  - `engine` *(Optional[Literal[\"c\", \"python\"]])*: Parser engine - `\"c\"`, `\"python\"`\n",
    "  - `na_values` *(Opional[List[str]])*: Additional strings to recognize as NA/NaN\n",
    "\n",
    "  **For Excel formats (.xls, .xlsx):**\n",
    "  - `sheet_name` *(Optional[str, int, List[Union[int, str]])*: Name or index of the sheet to read\n",
    "\n",
    "### Available methods\n",
    "\n",
    "`load_data(**kwargs)`\n",
    "\n",
    "Loads data from the specified file path and returns it as a pandas DataFrame.\n",
    "\n",
    "`load_schema()`\n",
    "\n",
    "Returns the original schema of the loaded data, including column names and data types. Available only for data in the *'.avro'* format.\n",
    "\n",
    "`save_data(df, **kwargs)`\n",
    "\n",
    "Saves a pandas DataFrame to the specified file path with(without) the configured format settings or schema.\n",
    "\n",
    "*Note:* For full documentation and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42612fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 1: Load CSV data with default settings\n",
    "\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "data_io = DataIO(path=\"../examples/example-data/housing.csv\")\n",
    "\n",
    "df = data_io.load_data()\n",
    "\n",
    "print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 2: Load CSV data with custom format settings\n",
    "\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "data_io = DataIO(\n",
    "    path=\"../examples/example-data/escaped_quoted_table.csv\",\n",
    "    sep=',',           # delimiter\n",
    "    quotechar='\"',     # quote character\n",
    "    quoting=\"minimal\", # quoting style\n",
    "    encoding='utf-8',  # encoding\n",
    "    header=0           # use first row as header\n",
    ")\n",
    "\n",
    "df = data_io.load_data()\n",
    "\n",
    "print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 3: Load data and get schema information\n",
    "\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "\n",
    "data_io = DataIO(path=\"../examples/example-data/avro_file.avro\")\n",
    "\n",
    "df = data_io.load_data()\n",
    "\n",
    "schema = data_io.load_schema()\n",
    "\n",
    "print(\"Data schema:\")\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 4: Save data to a file\n",
    "\n",
    "import pandas as pd\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'age': [25, 30, 35, 40, 45],\n",
    "    'city': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney']\n",
    "})\n",
    "\n",
    "\n",
    "data_io = DataIO(\n",
    "    path=\"../examples/example-data/sample_output.csv\",\n",
    "    sep=',',\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "\n",
    "data_io.save_data(sample_data)\n",
    "\n",
    "print(\"Data saved successfully to '../examples/example-data/sample_output.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
