{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5e143b",
   "metadata": {},
   "source": [
    "# Quick start\n",
    "\n",
    "*EPAM Syngen* is an unsupervised tabular data generation tool based on a variational autoencoder (VAE). \n",
    "It supports common tabular datatypes (floats, integers, datetime, text, categorical, binary) and can generate linked tables that sharing keys using the simple statistical approach. \n",
    "The SDK exposes simple programmatic entry points for training, inference, report generation, loading and saving data in supported formats - *CSV*, *Avro* and *Excel* format. The data should be located locally and be in UTF-8 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b1de2",
   "metadata": {},
   "source": [
    "This notebook demonstrates the SDK usage. Install the package and then you can call the main SDK class `Syngen` to run training, inference or generation of reports, and the class `DataIO` to load and save the data in supported formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe338621",
   "metadata": {},
   "source": [
    "Python *3.10* or *3.11* is required to run the library. The library is tested on Linux and Windows operating systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f88606",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "Please, install the library *syngen* (from Pypi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbdea6c32caa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ --use-pep517 --no-cache-dir syngen==0.10.28rc45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3ce41",
   "metadata": {},
   "source": [
    "# Class initialization\n",
    "\n",
    "```python\n",
    "Syngen(\n",
    "    metadata_path: Optional[str] = None,  # use a metadata file in the '.yaml', '.yml' format for a training or an inference of one or multiple tables to centralize all parameters in one place\n",
    "    table_name: Optional[str] = None,     # required for single-table training or inference process; an arbitrary string used to name the directories where artifacts are stored\n",
    "    source: Optional[str] = None,         # required for single-table training or inference process; a path to the file that you want to use as a reference\n",
    ")\n",
    "```\n",
    "### Attributes description:\n",
    "\n",
    "- **`metadata_path`** *(Optional[str], default: None)*: a path to a metadata file in *'.yaml'* or *'.yml'* format, used during training or inference to centralize all parameters for one or multiple tables.\n",
    "- **`table_name`** *(Optional[str], default: None)*: a required parameter for training or inference of a single table; an arbitrary string used to name the directories where artifacts are stored.\n",
    "- **`source`** *(Optional[str], default: None)*: a required parameter for single-table training or inference process; a path to the file that you want to use as a reference.\n",
    "\n",
    "***Note***: Both `source` and `table_name` are required when `metadata_path` is not provided. Use `metadata_path` to define multiple tables with or without relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1c86c",
   "metadata": {},
   "source": [
    "# Launch training\n",
    "\n",
    "You can start a training process using the SDK entrypoint `Syngen().train(...)`. This will train a model and save the model artifacts to a disk in the directory *'./model_artifacts'*. The SDK mirrors the CLI options so you can pass the same parameters programmatically. Below is a complete description of all available parameters:\n",
    "\n",
    "```python\n",
    "train(\n",
    "    self,\n",
    "    epochs: int = 10,                     # a number of training epochs\n",
    "    drop_null: bool = False,              # whether to drop rows with at least one missing value\n",
    "    row_limit: Optional[int] = None,      # a number of rows to train over\n",
    "    reports: Union[str, Tuple[str], List[str]] = \"none\",  # report types: \"none\", \"accuracy\", \"sample\", \"metrics_only\", \"all\"\n",
    "    log_level: Literal[\"TRACE\", \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"] = \"INFO\", # a logging level\n",
    "    batch_size: int = 32,                 # a training batch size\n",
    "    fernet_key: Optional[str] = None      # a name of the environment variable containing the Fernet key for secure storage of the data subset\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters description:\n",
    "\n",
    "- **`epochs`** *(int, default: 10)*: A number of training epochs. Must be ≥ 1. Since the early stopping mechanism is implemented the bigger value of epochs is the better.\n",
    "\n",
    "- **`drop_null`** *(bool, default: False)*: Whether to drop rows containing at least one missing value before training. When `False`, missing values are handled during the training process.\n",
    "\n",
    "- **`row_limit`** *(Optional[int], default: None)*: A maximum number of rows to use for training. If specified and less than the total rows, a random subset of the specified size will be selected. Useful for testing or working with large datasets.\n",
    "\n",
    "- **`reports`** *(Union[str, Tuple[str], List[str]], default: \"none\")*: Controls generation of quality reports. Accepts single string or list of strings:\n",
    "  - `\"none\"` - no reports generated (default)\n",
    "  - `\"accuracy\"` - generates an accuracy report comparing synthetic data (same size as original) with original dataset to estimate the quality of training process\n",
    "  - `\"sample\"` - generates a sample report showing distribution comparisons between the original data and the subset of this data\n",
    "  - `\"metrics_only\"` - outputs metrics to stdout without generation of an accuracy report\n",
    "  - `\"all\"` - generates both accuracy and sample reports\n",
    "\n",
    "  List example: `[\"accuracy\", \"sample\"]` to generate multiple report types\n",
    "\n",
    "  *Note*: Report generation may require significant time for large tables (>10,000 rows)\n",
    "\n",
    "- **`log_level`** *(str, default: \"INFO\")*: A logging level for the training process. Accepted values: `\"TRACE\"`, `\"DEBUG\"`, `\"INFO\"`, `\"WARNING\"`, `\"ERROR\"`, `\"CRITICAL\"`.\n",
    "\n",
    "- **`batch_size`** *(int, default: 32)*: A training batch size. Must be ≥ 1. Splits training into batches to optimize memory usage. Smaller batches use less RAM but may increase training time.\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: A name of the environment variable containing a 44-character URL-safe base64-encoded Fernet key. When provided, the data subset is encrypted on a disk (stored in the `.dat` format). If not provided, data is stored unencrypted in the `.pkl` format. **Important**: The same key must be used during an inference and a report generation to decrypt the data.\n",
    "\n",
    "*Note:* For full documentation, metadata file format, and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a8684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of training the single table\n",
    "\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "\n",
    "launcher_for_single_table = Syngen(\n",
    "    source=\"../examples/example-data/housing.csv\", \n",
    "    table_name=\"housing\"\n",
    ")\n",
    "\n",
    "launcher_for_single_table.train(\n",
    "    epochs=5,\n",
    "    drop_null=False,\n",
    "    row_limit=1000, \n",
    "    batch_size=32, \n",
    "    reports=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f378a17c58f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of training of multiple tables with relationships\n",
    "\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables = Syngen(\n",
    "    metadata_path=\"../examples/example-metadata/housing_metadata.yaml\"\n",
    ")\n",
    "\n",
    "launcher_for_multiple_tables.train(log_level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18988c75",
   "metadata": {},
   "source": [
    "The *'execution_artifacts'* attribute of the **Syngen** class provides information about the generated artifacts during the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(launcher_for_multiple_tables.execution_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf34c2c",
   "metadata": {},
   "source": [
    "# Launch generation of synthetic data\n",
    "\n",
    "You can start an inference process using the SDK entrypoint `Syngen().infer(...)`. The SDK mirrors the CLI options so you can pass the same parameters programmatically. Below is a complete description of all available parameters:\n",
    "\n",
    "```python\n",
    "infer(\n",
    "    self,\n",
    "    size: int = 100,                      # the desired number of rows to generate\n",
    "    run_parallel: bool = False,           # whether to use multiprocessing (feasible for tables > 5000 rows)\n",
    "    batch_size: Optional[int] = None,     # an inference batch size\n",
    "    random_seed: Optional[int] = None,    # if specified, generates a reproducible result\n",
    "    reports: Union[str, List[str]] = \"none\",  # report types: \"none\", \"accuracy\", \"metrics_only\", \"all\"\n",
    "    log_level: str = \"INFO\",              # a logging level\n",
    "    fernet_key: Optional[str] = None      # a name of the environment variable containing the Fernet key for decrypting the data subset\n",
    ")\n",
    "```\n",
    "### Parameters description:\n",
    "\n",
    "- **`size`** *(int, default: 100)*: The desired number of synthetic rows to generate. Must be ≥ 1.\n",
    "\n",
    "- **`run_parallel`** *(bool, default: False)*: Whether to use multiprocessing for data generation. Set to `True` to enable parallel processing, which is recommended and feasible for generating large tables (>5000 rows).\n",
    "\n",
    "- **`batch_size`** *(Optional[int], default: None)*: The inference batch size. Must be ≥ 1. If specified, the generation is split into batches to optimize memory usage and save RAM.\n",
    "\n",
    "- **`random_seed`** *(Optional[int], default: None)*: A random seed for reproducible generation. Must be ≥ 0.\n",
    "\n",
    "- **`reports`** *(Union[str, Tuple[str], List[str]], default: \"none\")*: Controls generation of quality reports. Accepts single string or list of strings:\n",
    "  - `\"none\"` - no reports generated (default)\n",
    "  - `\"accuracy\"` - generates an accuracy report comparing original and synthetic data patterns to verify quality of a generated data\n",
    "  - `\"metrics_only\"` - outputs metrics to stdout without generating an accuracy report\n",
    "  - `\"all\"` - generates an accuracy report (same as `\"accuracy\"`)\n",
    "\n",
    "  List example: `[\"accuracy\", \"metrics_only\"]` to generate multiple report types\n",
    "\n",
    "  *Note*: Report generation may require significant time for large generated tables (>10,000 rows)\n",
    "\n",
    "- **`log_level`** *(str, default: \"INFO\")*: A logging level for the inference process. Accepted values: `\"TRACE\"`, `\"DEBUG\"`, `\"INFO\"`, `\"WARNING\"`, `\"ERROR\"`, `\"CRITICAL\"`.\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: A name of the environment variable containing a 44-character URL-safe base64-encoded Fernet key. When provided, the data subset is decrypted for a report generation. **Important**: The same key used during a training must be used during a report generation to successfully decrypt the data.\n",
    "\n",
    "*Note:* For full documentation, metadata file format, and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of inference for the single table\n",
    "\n",
    "launcher_for_single_table.infer(\n",
    "    size=200,\n",
    "    run_parallel=False,\n",
    "    batch_size=32, \n",
    "    random_seed=42,\n",
    "    reports=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example of inference of multiple tables with relationships\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.infer(log_level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd28f7",
   "metadata": {},
   "source": [
    "The *'execution_artifacts'* attribute of the **Syngen** class provides information about the generated artifacts during the inference process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(launcher_for_multiple_tables.execution_artifacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a6385",
   "metadata": {},
   "source": [
    "# Data security: Using Fernet Key for encryption\n",
    "\n",
    "In the current implementation, a sample of the original data is stored on a disk during a training process. To ensure data security and protect sensitive information, you can use a **Fernet key** to encrypt this data.\n",
    "\n",
    "## What is a Fernet Key?\n",
    "\n",
    "A Fernet key is a 44-character URL-safe base64-encoded string used for symmetric encryption. When provided, the data subset is encrypted on a disk (stored in the `.dat` format instead of unencrypted `.pkl` format).\n",
    "\n",
    "## How to Generate a Fernet Key\n",
    "\n",
    "You can generate a Fernet key using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cee26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Fernet key\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "fernet_key = Fernet.generate_key().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd259dc",
   "metadata": {},
   "source": [
    "## Setting the Fernet Key as an environment variable\n",
    "\n",
    "After generating the key, you need to store it as an environment variable. This can be done in your terminal or programmatically in Python.\n",
    "\n",
    "### Option 1: Set in Terminal (Linux/macOS)\n",
    "\n",
    "```bash\n",
    "export MY_FERNET_KEY='your_generated_fernet_key_here'\n",
    "```\n",
    "\n",
    "### Option 2: Set in Terminal (Windows)\n",
    "\n",
    "```cmd\n",
    "set MY_FERNET_KEY=your_generated_fernet_key_here\n",
    "```\n",
    "\n",
    "### Option 3: Set programmatically in Python\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ['MY_FERNET_KEY'] = 'your_generated_fernet_key_here'\n",
    "```\n",
    "\n",
    "## Using the Fernet Key in a training\n",
    "\n",
    "When training with encryption, pass the name of the environment variable (not the Fernet key itself) to the `fernet_key` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ece919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example: the training with the Fernet key encryption\n",
    "\n",
    "import os\n",
    "from syngen.sdk import Syngen\n",
    "\n",
    "# Step 1: Set the Fernet key as an environment variable\n",
    "os.environ[\"MY_FERNET_KEY\"] = fernet_key  # Using the key generated above\n",
    "\n",
    "# Step 2: Train with encryption enabled\n",
    "\n",
    "launcher_for_encrypted_data = Syngen(\n",
    "    source=\"../examples/example-data/housing.csv\", \n",
    "    table_name=\"housing_encrypted\"\n",
    ")\n",
    "\n",
    "launcher_for_encrypted_data.train(\n",
    "    epochs=5,\n",
    "    row_limit=1000, \n",
    "    batch_size=32, \n",
    "    fernet_key=\"MY_FERNET_KEY\"  # Pass the environment variable name, not the key itself\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed5c1b",
   "metadata": {},
   "source": [
    "## Using the Fernet Key in an inference\n",
    "\n",
    "**Important**: When generating synthetic data during an inference process, you must use the **same Fernet key** that was used during a training process. This allows the system to decrypt the stored data subset for a report generation.\n",
    "\n",
    "If the Fernet key is not provided or doesn't match the Fernet key used in the training process, the inference process will fail when trying to access the encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d3788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Inference with Fernet key decryption\n",
    "# The environment variable 'MY_FERNET_KEY' is already set from the training step\n",
    "\n",
    "# Inference with the same Fernet key\n",
    "launcher_for_encrypted_data.infer(\n",
    "    size=200,\n",
    "    batch_size=32, \n",
    "    random_seed=42,\n",
    "    reports=\"all\",\n",
    "    fernet_key=\"MY_FERNET_KEY\"  # Must use the same key as in a training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3232e8",
   "metadata": {},
   "source": [
    "## Using the Fernet Key with the metadata file\n",
    "\n",
    "You can also specify the Fernet key in the metadata file for both training and inference:\n",
    "\n",
    "```yaml\n",
    "global:\n",
    "  encryption:\n",
    "    fernet_key: MY_FERNET_KEY  # Name of the environment variable\n",
    "\n",
    "TABLE_NAME:\n",
    "  train_settings:\n",
    "    source: \"./data/table.csv\"\n",
    "  \n",
    "  infer_settings:\n",
    "    size: 100\n",
    "  \n",
    "  # You can also specify per-table encryption\n",
    "  encryption:\n",
    "    fernet_key: MY_FERNET_KEY\n",
    "```\n",
    "\n",
    "Then use it in your code:\n",
    "\n",
    "```python\n",
    "# Training with the metadata file and the Fernet key\n",
    "Syngen(metadata_path=\"path/to/metadata.yaml\").train()\n",
    "\n",
    "# Inference with the metadata file and the Fernet key\n",
    "Syngen(metadata_path=\"path/to/metadata.yaml\").infer()\n",
    "```\n",
    "\n",
    "## Important security notes\n",
    "\n",
    "⚠️ **Critical security considerations:**\n",
    "\n",
    "1. **Store the key securely**: Never hardcode the Fernet key directly in your code or commit it to version control systems.\n",
    "2. **Key recovery is impossible**: If you lose the Fernet key, encrypted data cannot be recovered\n",
    "3. **Same key required**: Always use the same Fernet key for a training, an inference and a report generation\n",
    "4. **Environment variable**: Use an environment variable to store the Fernet key securely\n",
    "5. **Key length**: The Fernet key must be exactly 44 characters (URL-safe base64-encoded)\n",
    "6. **Production environments**: In production, use secure secret management services (AWS Secrets Manager, Azure Key Vault, HashiCorp Vault, etc.)\n",
    "\n",
    "## What happens without a Fernet key?\n",
    "\n",
    "If you don't provide a `fernet_key` parameter:\n",
    "- Data subset is stored **unencrypted** in the `.pkl` format\n",
    "- No decryption is needed during the inference or the report generation\n",
    "- Suitable for non-sensitive data or development environments\n",
    "\n",
    "With a `fernet_key`:\n",
    "- Data subset is stored **encrypted** in the `.dat` format\n",
    "- Decryption is required during the inference or the report generation using the same Fernet key\n",
    "- Recommended for sensitive or production data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e90b1a",
   "metadata": {},
   "source": [
    "# Generate quality reports separately\n",
    "\n",
    "Sometimes you may want to generate quality reports separately after training or/and inference has already been completed to evaluate the quality of the input data or the generated data. The SDK provides the `Syngen().generate_quality_reports(...)` method that allows you to generate quality reports for a table using existing artifacts without re-running the training or/and inference processes.\n",
    "\n",
    "This method is useful when:\n",
    "- You completed training/inference without quality reports (with `reports=\"none\"`)\n",
    "- You want to generate additional report types later\n",
    "- You want to separate the computation-intensive training/inference from report generation\n",
    "\n",
    "\n",
    "```python\n",
    "generate_quality_reports(\n",
    "    self,\n",
    "    table_name: str,                        # required: the name of the table to generate quality reports for\n",
    "    reports: Union[str, Tuple[str], List[str]], # required: report types to generate\n",
    "    fernet_key: Optional[str] = None        # optional: a Fernet key for decrypting encrypted data\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters description:\n",
    "\n",
    "- **`table_name`** *(str, required)*: The name of the table to generate reports for.\n",
    "\n",
    "- **`reports`** *(Union[str, Tuple[str], List[str]], required)*: Controls which quality reports to generate. Accepts single string or list of strings:\n",
    "  - `\"accuracy\"` - generates an accuracy report comparing original and synthetic data\n",
    "  - `\"metrics_only\"` - outputs metrics information to stdout without generating an accuracy report\n",
    "  - `\"sample\"` - generates a sample report showing distribution comparisons between original data and the data subset used for a training process\n",
    "  - `\"all\"` - generates all available reports (*\"accuracy\"* and *\"sample\"*)\n",
    "  \n",
    "  List example: `[\"accuracy\", \"sample\"]` to generate multiple report types.\n",
    "\n",
    "  *Note*: Report generation may require significant time for large tables (>10,000 rows)\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: The name of the environment variable containing the Fernet key used to decrypt the original data subset. **Important**: Must be the same key used during training if the data was encrypted.\n",
    "\n",
    "### Required artifacts\n",
    "\n",
    "To generate quality reports, the following artifacts must exist:\n",
    "\n",
    "**For accuracy reports (`\"accuracy\"` or `\"metrics_only\"`):**\n",
    "- Training must be completed successfully\n",
    "- Inference must be completed successfully\n",
    "\n",
    "**For a `\"sample\"` report:**\n",
    "- Training must be completed successfully\n",
    "\n",
    "### Key notes:\n",
    "\n",
    "- The method uses existing artifacts and does not re-run a training or an inference process\n",
    "- All required artifacts must be present in the `model_artifacts` directory\n",
    "- The `table_name` must match exactly the name of the `table_name` that was used in a training/inference process\n",
    "- If data was encrypted during a training, the same `fernet_key` must be provided\n",
    "\n",
    "*Note:* For full documentation and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f71f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Generate an accuracy report after a training and inference completed without a generation of quality reports\n",
    "\n",
    "# Assume a training and inference were already completed with reports=\"none\"\n",
    "# Now generate an accuracy report separately\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_conditions\",\n",
    "    reports=\"accuracy\",\n",
    "    log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Generate a sample report after training completed\n",
    "\n",
    "# Generate a sample report to compare original data with its subset\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_properties\",\n",
    "    reports=\"sample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Generate multiple reports at once\n",
    "\n",
    "# Generate both accuracy and sample reports\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_conditions\",\n",
    "    reports=[\"accuracy\", \"sample\"]\n",
    ")\n",
    "\n",
    "# Or use \"all\" to generate all available reports\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing_conditions\",\n",
    "    reports=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b32f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Generate quality reports for encrypted data\n",
    "import os\n",
    "\n",
    "# Ensure the Fernet key environment variable is set\n",
    "# (Should be the same key used during training)\n",
    "os.environ['MY_FERNET_KEY'] = fernet_key\n",
    "\n",
    "# Generate qulaity reports with decryption\n",
    "launcher_for_encrypted_data.generate_quality_reports(\n",
    "    table_name=\"housing_encrypted\",\n",
    "    reports=\"accuracy\",\n",
    "    fernet_key=\"MY_FERNET_KEY\"  # Same key used in training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed62d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Generate the \"metrics_only\" report (without a full accuracy report)\n",
    "# Output metrics to stdout\n",
    "\n",
    "\n",
    "launcher_for_multiple_tables.generate_quality_reports(\n",
    "    table_name=\"housing\",\n",
    "    reports=\"metrics_only\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05167a9e",
   "metadata": {},
   "source": [
    "# Data loading and saving: DataIO class\n",
    "\n",
    "The SDK provides the `DataIO` class for loading and saving data in various supported formats with optional encryption and format settings. This class is useful when you need to:\n",
    "- Load and save data in different file formats (*CSV*, *Avro*, *Excel*, etc.)\n",
    "- Load and save data with specific format settings\n",
    "- Work with encrypted data files\n",
    "\n",
    "## Class initialization\n",
    "\n",
    "```python\n",
    "DataIO(\n",
    "    path: str,                          # required: a path to the data file\n",
    "    fernet_key: Optional[str] = None,   # optional: a Fernet key for encrypted data\n",
    "    **kwargs                            # optional: format settings for CSV or Excel tables, or schema for AVRO file\n",
    ")\n",
    "```\n",
    "\n",
    "### Parameters description:\n",
    "\n",
    "- **`path`** *(str, required)*: the path to the data file to load or save. Supported formats include:\n",
    "  - CSV files: `.csv`, `.psv`, `.tsv`, `.txt`\n",
    "  - Avro files: `.avro`\n",
    "  - Excel files: `.xls`, `.xlsx`\n",
    "\n",
    "- **`fernet_key`** *(Optional[str], default: None)*: the name of the environment variable containing the Fernet key for encrypted data operations.\n",
    "\n",
    "- **`**kwargs`**: Optional format settings or/and a schema for reading and writing data. Available parameters depend on the file format:\n",
    "\n",
    "  **For tables in '.csv', '.psv', '.tsv', '.txt' formats:**\n",
    "  - `sep` *(str)*: Delimiter to use (e.g., `','`, `';'`, `'\\t'`)\n",
    "  - `quotechar` *(str)*: Character used to denote the start and end of a quoted item (default: `'\"'`)\n",
    "  - `quoting` *(str)*: Quoting behavior - `\"all\"`, `\"minimal\"`, `\"non-numeric\"`, `\"none\"`\n",
    "  - `escapechar` *(str)*: Character used to escape other characters\n",
    "  - `encoding` *(str)*: Encoding to use (e.g., `'utf-8'`, `'latin-1'`)\n",
    "  - `header` *(Optional[int, List[int], Literal[\"infer\"]])*: Row number(s) containing column labels and marking the start of the data\n",
    "  - `skiprows` *(Optional[int, List[int]])*: Lines to skip at the start of the file\n",
    "  - `on_bad_lines` *(Literal[\"error\", \"warn\", \"skip\"])*: Action on bad lines - `\"error\"`, `\"warn\"`, `\"skip\"`\n",
    "  - `engine` *(Optional[Literal[\"c\", \"python\"]])*: Parser engine - `\"c\"`, `\"python\"`\n",
    "  - `na_values` *(Opional[List[str]])*: Additional strings to recognize as NA/NaN\n",
    "\n",
    "  **For Excel formats (.xls, .xlsx):**\n",
    "  - `sheet_name` *(Optional[str, int, List[Union[int, str]])*: Name or index of the sheet to read\n",
    "\n",
    "### Available methods\n",
    "\n",
    "`load_data(**kwargs)`\n",
    "\n",
    "Loads data from the specified file path and returns it as a pandas DataFrame.\n",
    "\n",
    "`load_schema()`\n",
    "\n",
    "Returns the original schema of the loaded data, including column names and data types. Available only for data in the *'.avro'* format.\n",
    "\n",
    "`save_data(df, **kwargs)`\n",
    "\n",
    "Saves a pandas DataFrame to the specified file path with(without) the configured format settings or schema.\n",
    "\n",
    "*Note:* For full documentation and additional details, please refer to [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42612fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 1: Load CSV data with default settings\n",
    "\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "data_io = DataIO(path=\"../examples/example-data/housing.csv\")\n",
    "\n",
    "df = data_io.load_data()\n",
    "\n",
    "print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 2: Load CSV data with custom format settings\n",
    "\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "data_io = DataIO(\n",
    "    path=\"../examples/example-data/escaped_quoted_table.csv\",\n",
    "    sep=',',           # delimiter\n",
    "    quotechar='\"',     # quote character\n",
    "    quoting=\"minimal\", # quoting style\n",
    "    encoding='utf-8',  # encoding\n",
    "    header=0           # use first row as header\n",
    ")\n",
    "\n",
    "df = data_io.load_data()\n",
    "\n",
    "print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 3: Load data and get schema information\n",
    "\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "\n",
    "data_io = DataIO(path=\"../examples/example-data/avro_file.avro\")\n",
    "\n",
    "df = data_io.load_data()\n",
    "\n",
    "schema = data_io.load_schema()\n",
    "\n",
    "print(\"Data schema:\")\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example 4: Save data to a file\n",
    "\n",
    "import pandas as pd\n",
    "from syngen.sdk import DataIO\n",
    "\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'age': [25, 30, 35, 40, 45],\n",
    "    'city': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney']\n",
    "})\n",
    "\n",
    "\n",
    "data_io = DataIO(\n",
    "    path=\"../examples/example-data/sample_output.csv\",\n",
    "    sep=',',\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "\n",
    "data_io.save_data(sample_data)\n",
    "\n",
    "print(\"Data saved successfully to '../examples/example-data/sample_output.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
